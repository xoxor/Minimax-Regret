% IJCAI-21 Author's response

% Template file with author's reponse

\documentclass{article}
\pdfpagewidth=8.5in
\pdfpageheight=11in
\usepackage{ijcai21-authors-response}


\usepackage{times}
\usepackage{soul}
\usepackage{url}
\usepackage[hidelinks]{hyperref}
\usepackage[utf8]{inputenc}
\usepackage[small]{caption}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{booktabs}
\usepackage{algorithm}
\usepackage{algorithmic}
\usepackage{lipsum}
\urlstyle{same}

\newtheorem{example}{Example}
\newtheorem{theorem}{Theorem}

\usepackage{color}

\newcommand{\commentOC}[1]{\textcolor{blue}{\small$\big[$OC: #1$\big]$}}
\newcommand{\commentBN}[1]{\textcolor{magenta}{\small$\big[$BN: #1$\big]$}}
\newcommand{\commentPV}[1]{\textcolor{red}{\small$\big[$PV: #1$\big]$}}

\begin{document}
%Working around the censorship.
\addtocounter{pagecount}{-4}

	We thank the reviewers for their comments. We specify that the questions reported are not verbatim for lack of space and focus on factual errors. 
\paragraph{Review $\#$2 writes as a weakness that “the method proposed here is not compared with others”.}
We believe it is erroneous to consider the lack of comparison a weakness. The simultaneous elicitation of both the voting rule and the agents preferences is a novel setting and, as far as we know, there is no competitor from the state-of-the-art to compare with. 
We are not aware of any method that elicits the voting rule we could compare with – the work by Cailloux and Endriss [2014] does not consider PSRs. Nevertheless, the Two Phases strategy was designed to challenge our interleaving approach by comparing it with a more classical sequential method, which (when first eliciting the rule and then the agents preferences) coincides with the method of Lu and Boutilier [2011] for preferences elicitation with a fixed voting rule.
%\paragraph{Review $\#$2: “Only variants of the same methods are compared with each others”.}
%\commentOC{Isn’t this a bit arguable that Elitist is very different rather than a variant?}
The Elitist strategy has a very different approach than the Pessimistic one, to the point that it cannot be considered a variant. They are compared in a situation specifically tailored to advantage the Elitist. 

\paragraph{Review $\#$2: “the voting rule has to be defined independently of the preferences of the voters. And probably not by the chairpersonn who may influence the result by choosing the weights”.}
It is not true that any decision process involving preference aggregation requires a voting rule defined beforehand, nor that it is necessarily a bad idea to let a chair decide on the voting rule. The interest of considering incomplete knowledge in the voting rule has been advocated in a recent survey paper of a leading researcher in Computational Social Choice [Lang 2020, \href{https://doi.org/10.24963/ijcai.2020/680}{doi: 10.24963/ijcai.2020/680}]. The case of IJCAI aggregation process of reviews illustrates the point: reviewers provide their preferences despite ignoring how these will be aggregated. The Introduction section of our article provides another example.

\paragraph{Review $\#$32 suggests that it is hard to find “any real setting where a third party decides who wins a vote, not the chair. (…) Why would voters participate in a voting rule that is not public or common knowledge? (…) If the chair can compute winners over and over for every elicitation for arbitrary size profiles, why wouldn't the chair just compute the real winner himself or herself, rather the delegate to the third party? (…) Why is this easier than reflecting on the relative weights?”}
It is not true that such setting is uncommon, on the contrary. Other than the example we provided in the Introduction, we could consider the reviewing process of a conference where the best paper must be elected. In this context, the agents express their preferences on the papers they reviewed, but they are not aware of the voting rule the Program Chair will apply when aggregating them. Nonetheless, reviewers are still willing to participate in the process. 
Also, the PC may not have a specific voting rule in mind, and she will find it hard to provide a precise scoring vector if asked. Maybe she strongly believes that being ranked once in the first position is “much more” valuable than being ranked two times second, but does not know exactly how much more (though she can judge example cases). This is similar to how the paper WeBuildAI (and the general literature in micro-economy) supposes that participants are able to compare pairs of matches, but does not assume that participants can explicit their utility functions. 

Methodologically speaking, phrasing questions in terms of winners out of profiles is arguably the most fundamental and natural view of what a social choice function is. Talking in terms of weights is a synthetic construction that could lead to different judgments by participants than other constructions. 
For example, PSRs can also be described in terms of distance to ideal profiles (On the role of distances in defining voting rules, Elkind et al., AAMAS 2010). 
There is no a priori reason to believe that questioning the chair in terms of this different parametric space would yield logically equivalent answers: research in experimental psychology shows that participants’ answers differ widely when changing the phrasing of preference-related questions [Lichtenstein \& Slovic, 2012, \href{https://doi.org/10.1017/CBO9780511618031}{doi: 10.1017/CBO9780511618031}].
To get out of such conundrums, we need a language considered “fundamental”. Questions of the form “In this profile, who should win?” arguably provides such a natural language.

Also, it is a classical assumption in political science that the chair could delegate to a third party, for example, because the chair wants to satisfy a form of fairness which she thinks that algorithm satisfies. In our case, this is done by agreeing to let the principle of “min-max regret” decide instead of picking her favorite winner.

%\paragraph{Review $\#$32: Why would the chair give up control of choosing the winner?”.}
\textit{\textbf{}}
%Specifying general algorithms is demanding, hence, we adapt a mechanism used in a real life experiment by Giritligil et al. [2005] in a novel way for the setting of elicitation of positioning scoring rules (PSRs). 

%Note that the chair cannot compute the real winner as she ignores the profile. 

\textit{\textbf{Is Figure 1 for the synthetic data? Please specify. Why is Figure 2 shown for only Pessimistic, not all the approaches?}}

%-Is Figure 1 for the synthetic data? Please specify. Same question for Tables 2 and 3. In Figure 2, are the m=N,n=N lines the synthetic data?
%-Why is Figure 2 shown for only Pessimistic, not all the approaches? Were all approaches tested on all data sets? Or were all approaches only tested on synthetic data?
Yes, when we do not specify the name of the dataset we mean data generated following the procedure described in Sec 5. Regarding the real datasets, we only tested the Pessimistic strategy for the following reasons: $1)$ Random was considered only as a baseline in the first experiment, which shows that Pessimistic performs much better; $2)$ As pointed out in Sec 4, Extended Pessimistic is too computationally costly to run on larger instances; \commentBN{I would keep the old phrasing to keep the same structure for all points (Extended Pessimistic ... as pointed out)} $3)$ Elitist was designed with the only purpose of challenging our best strategy (Pessimistic) in extreme cases tailored to favor the former. Testing this strategy in other settings does not yield interesting information; $4)$ Two Phases was designed to compare our interleaving approach to a more classical linear method. We thought that the most challenging situation (Impartial Culture) was the best setting to perform this test. \commentOC{What does the last sentence answer?}\commentBN{To why we didn't test Two Phases with real datasets.}



\paragraph{Rebuttal to Reviewer $\#$56: specific questions}.\\
\textit{\textbf{Can you clarify better the rationale behind the assumptions you make on questions to the chair?}}

The question is asked by showing a profile and asking who should win; the response is encoded as a constraint and added to the system’s knowledge. Phrasing questions in terms of winners out of profiles is arguably the most fundamental and natural view of what a social choice function is (as pointed out in our response to reviewer $\#$32). We adapt a mechanism used in a real life experiment by Giritligil et al. [2005] in a novel way for the elicitation of PSRs.
%Note that we want to ask an informative query: the elicitation strategy decides which question to be asked, and, if it is of the “chair” type, the strategy decides the linear constraint to check; this is then translated to a profile.

\textit{\textbf{Could you elaborate on why you think is reasonable to assume the human chair will answer hundreds of questions?}}

%We assume the chair to be human and, as discussed in the paragraph “Building concrete questions for the chair“ on page 3, we view questions “what is the winner of this profile” to be easier to answer than directly asking the weights (in the same way as, for the problem of elicitation an utility function, one would ask comparison queries rather than asking directly utility values). 
Note that, in our experiments, we often plot the total number of questions in order to have a simple way to compare the total elicitation cost. 
\commentOC{I’d remove this first sentence and rephrase the next one.}
Table 1 of Appendix shows that the number of questions posed to the chair (and each agent) is usually not that big.\commentOC{I suggest: is small or is usually small, and we have to phrase explicitly that the assumption in the question is wrong.}
When the profile is quite homogeneous (see the lines corresponding to real datasets) this number is very low or even zero in case of clear winner. We also mention that the process could be terminated early: after a fixed number of questions (the “approximate winner” is the alternative with lowest regret); or after reaching a "low enough" regret.
%In fact the number of questions asked to the chair using the Pessimistic strategy (as shown in the appendix) is often quite small  (e.g. zero in skate and "courses", 8.4 in m5n10, 13 in m5n20, 30 in tshirt,...), this is because the strategy does a good job of asking the question that gives more information, and often only “sparse” information about the voting rule is enough. Similarly, the average number of questions asked to a voter is also reasonable (e.g questions per agent 6.5 in courses, 6.1 in m5n10,  )
%: X.X in Experiment YY, for instance. In Table 2, the (10,20) example shows that to reach a “low” regret -that we define as n/10- we need to ask 340 questions. This number should be divided among the voters and the chair, resulting in ~ 10 questions per voter, which we consider a reasonable amount. The fact that asking too many questions to the chair is not worth it isworth is also displayed in Table 3 in the main text.
%Finally, note that the process could be terminated early: e.g. one could decide to stop after a fixed number of questions (even if regret is not zero) and to output as an “approximate winner” the alternative with lowest minimax regret value.
If the paper will be accepted, we will stress more this point and include the Appendix Table in the final version.


\end{document}

