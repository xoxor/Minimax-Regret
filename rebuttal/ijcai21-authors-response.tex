% IJCAI-21 Author's response

% Template file with author's reponse

\documentclass{article}
\pdfpagewidth=8.5in
\pdfpageheight=11in
\usepackage{ijcai21-authors-response}


\usepackage{times}
\usepackage{soul}
\usepackage{url}
\usepackage[hidelinks]{hyperref}
\usepackage[utf8]{inputenc}
\usepackage[small]{caption}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{booktabs}
\usepackage{algorithm}
\usepackage{algorithmic}
\usepackage{lipsum}
\urlstyle{same}

\newtheorem{example}{Example}
\newtheorem{theorem}{Theorem}

\usepackage{color}

\newcommand{\commentOC}[1]{\textcolor{blue}{\small$\big[$OC: #1$\big]$}}
\newcommand{\commentBN}[1]{\textcolor{magenta}{\small$\big[$BN: #1$\big]$}}
\newcommand{\commentPV}[1]{\textcolor{red}{\small$\big[$PV: #1$\big]$}}

\begin{document}
%Working around the censorship.
\addtocounter{pagecount}{-4}

	We thank the reviewers for their comments. We specify that the questions reported are not verbatim for lack of space. 
\paragraph{Rebuttal to Reviewer $\#$2: factual error}.\\
\textit{\textbf{One of the weaknesses is that the method proposed is not compared with others.}}

\commentOC{I suggest to remove “factual error” and “specific questions” and rather directly go with the first question.} \commentBN{I'm not against removing it but I thought it was better to specify why we are replying. In the FAQ for the AC there is a question 1) "What should I do if the authors have sent a response?" the answer is "You have to check whether the response really points out a factual error in a review or unethical issues.etc etc" 2)"Can reviewers ask specific questions to the authors, that they should answer during the response phase?" the answer is "In principle, No. etc etc". I'm afraid the AC won't send the respond to the reviewer if he feels we're just using it to contest his opinion.}
We believe it is erroneous to consider the lack of comparison a weakness. The simultaneous elicitation of both the voting rule and the agents preferences is a novel setting and, as far as we know, there is no clear competitor from the state-of-the-art to compare with. However, please note that we designed all the strategies to challenge one another. $1)$ The Elitist has a very different approach than the Pessimistic to the point that it cannot be considered a variant. We compared these two strategies in a situation specifically tailored to advantage the Elitist. $2)$ The Two Phases was designed to challenge our interleaving approach by comparing it with a more classical linear \commentPV{I don't like calling "linear" the classic method of first eliciting the rule and then the agents. But I am unsure about an alternative, maybe "sequential"?} method: first elicit the rule and then the agents preferences or vice versa. The former coincides with the method of Lu and Boutilier [2011] for preferences elicitation fixed the voting rule.
We are not aware of any method that elicits the voting rule we could compare with —the work by Cailloux and Endriss [2014] does not consider PSRs.

\textit{\textbf{The voting rule has to be defined independently of the voters preferences and not by the chairperson.}}

It is not true that any decision process involving preference aggregation requires a voting rule defined beforehand, nor that it is necessarily a bad idea to let a chair decide on the voting rule. The interest of considering incomplete knowledge in the voting rule has been advocated in a recent survey paper of a leading researcher in Computational Social Choice [Lang 2020, \url{https://doi.org/10.24963/ijcai.2020/680}]. The case of IJCAI aggregation process of reviews illustrates the point: reviewers provide their preferences despite ignoring how these will be aggregated. The Introduction section of our article provides another example.

\paragraph{Rebuttal to Reviewer $\#$32: specific questions}
.[Although not in the proper section, the reviewer formulated questions in the format described by the FAQ on when to answer.]

\textit{\textbf{Can the authors give an example of when the setting may occur in practice? Why would voters participate without knowing the voting rule? Why selecting winners is easier than reflecting on weights or computing the winner herself?}}

Other than the example we provided in the Introduction, we could consider the reviewing process of a conference where the best paper must be elected. In this context, the agents express their preferences on the papers they reviewed, but they are not aware of the voting rule the Program Chair will apply when aggregating them. %Nonetheless, reviewers are still willing to participate in the process. 
Also, the PC may not have a specific voting rule in mind, and she will find it hard to provide a precise scoring vector if asked. Imagine, for the sake of the example, that all the reviewers review all the papers and they rank them according to their preferences. The PC member could adopt the Borda count and pick the paper with the highest score, but this is not the most appealing method. Maybe she strongly believes that being ranked once in the first position is “much more” valuable than being ranked two times second, but does not know exactly how much more (though she can judge example cases). This is similar to how the paper WeBuildAI (and the general literature in micro-economy) supposes that participants are able to compare pairs of matches, but does not assume that participants can explicit their utility functions. Methodologically speaking, phrasing questions in terms of winners out of profiles is arguably the most fundamental and natural view of what a social choice function is. Talking in terms of weights is a synthetic construction that could lead to different judgments by participants than other constructions. \commentOC{I find it important that the two next commented-out sentences be somehow included.}
%For example, PSRs can also be described in terms of distance to ideal profiles ( On the role of distances in defining voting rules, Elkind et al., AAMAS 2010). 
%There is no a priori reason to believe that questioning the chair in terms of this different parametric space would yield logically equivalent answers: 
A research in experimental psychology shows that participants’ answers differ widely when changing the phrasing of preference-related questions [Lichtenstein \& Slovic, 2012, \href{https://doi.org/10.1017/CBO9780511618031}{doi: 10.1017/CBO9780511618031}].
%(Lichtenstein, Slovic - The Construction of Preference, Cambridge University Press, 2006). 
To get out of such conundrums, we need a language considered “fundamental”. Questions of the form “In this profile, who should win?” arguably provides such a natural language.
%Specifying general algorithms is demanding, hence, we adapt a mechanism used in a real life experiment by Giritligil et al. [2005] in a novel way for the setting of elicitation of positioning scoring rules (PSRs). 

%Finally, the chair could delegate to a third party, by agreeing to let the principle of “min-max regret” decide instead of picking her favorite winner, for example, because the chair wants to satisfy a form of fairness which she thinks that algorithm satisfies. This is a classical assumption in political science. 
%Note that the chair cannot compute the real winner as she ignores the profile. 

\textit{\textbf{Is Figure 1 for the synthetic data? Please specify. Why is Figure 2 shown for only Pessimistic, not all the approaches?}}

%-Is Figure 1 for the synthetic data? Please specify. Same question for Tables 2 and 3. In Figure 2, are the m=N,n=N lines the synthetic data?
%-Why is Figure 2 shown for only Pessimistic, not all the approaches? Were all approaches tested on all data sets? Or were all approaches only tested on synthetic data?
Yes, when we do not specify the name of the dataset we mean data generated following the procedure described in Sec 5. Regarding the real datasets, we only tested the Pessimistic strategy for the following reasons: $1)$ Random was considered only as a baseline in the first experiment, which shows that Pessimistic performs much better; $2)$ As pointed out in Sec 4, Extended Pessimistic is too computationally costly to run on larger instances; $3)$ Elitist was designed with the only purpose of challenging our best strategy (Pessimistic) in extreme cases tailored to favor the former. Testing this strategy in other settings does not yield interesting information; $4)$ Two Phases was designed to compare our interleaving approach to a more classical linear method. We thought that the most challenging situation (Impartial Culture) was the best setting to perform this test. \commentOC{What does the last sentence answer?}\commentBN{To why we didn't test Two Phases with real datasets.}



\paragraph{Rebuttal to Reviewer $\#$56: specific questions}.\\
\textit{\textbf{Can you clarify better the rationale behind the assumptions you make on questions to the chair?}}

The question is asked by showing a profile and asking who should win; the response is encoded as a constraint and added to the system’s knowledge. Phrasing questions in terms of winners out of profiles is arguably the most fundamental and natural view of what a social choice function is (as pointed out in our response to reviewer $\#$32). We adapt a mechanism used in a real life experiment by Giritligil et al. [2005] in a novel way for the elicitation of PSRs.
%Note that we want to ask an informative query: the elicitation strategy decides which question to be asked, and, if it is of the “chair” type, the strategy decides the linear constraint to check; this is then translated to a profile.

\textit{\textbf{Could you elaborate on why you think is reasonable to assume the human chair will answer hundreds of questions?}}

%We assume the chair to be human and, as discussed in the paragraph “Building concrete questions for the chair“ on page 3, we view questions “what is the winner of this profile” to be easier to answer than directly asking the weights (in the same way as, for the problem of elicitation an utility function, one would ask comparison queries rather than asking directly utility values). 
Note that, in our experiments, we often plot the total number of questions in order to have a simple way to compare the total elicitation cost. 
\commentOC{I’d remove this first sentence and rephrase the next one.}
Table 1 of Appendix shows that the number of questions posed to the chair (and each agent) is usually not that big.\commentOC{I suggest: is small or is usually small, and we have to phrase explicitly that the assumption in the question is wrong.}
When the profile is quite homogeneous (see the lines corresponding to real datasets) this number is very low or even zero in case of clear winner. We also mention that the process could be terminated early: after a fixed number of questions (the “approximate winner” is the alternative with lowest regret); or after reaching a "low enough" regret.
%In fact the number of questions asked to the chair using the Pessimistic strategy (as shown in the appendix) is often quite small  (e.g. zero in skate and "courses", 8.4 in m5n10, 13 in m5n20, 30 in tshirt,...), this is because the strategy does a good job of asking the question that gives more information, and often only “sparse” information about the voting rule is enough. Similarly, the average number of questions asked to a voter is also reasonable (e.g questions per agent 6.5 in courses, 6.1 in m5n10,  )
%: X.X in Experiment YY, for instance. In Table 2, the (10,20) example shows that to reach a “low” regret -that we define as n/10- we need to ask 340 questions. This number should be divided among the voters and the chair, resulting in ~ 10 questions per voter, which we consider a reasonable amount. The fact that asking too many questions to the chair is not worth it isworth is also displayed in Table 3 in the main text.
%Finally, note that the process could be terminated early: e.g. one could decide to stop after a fixed number of questions (even if regret is not zero) and to output as an “approximate winner” the alternative with lowest minimax regret value.
If the paper will be accepted, we will stress more this point and include the Appendix Table in the final version.


\end{document}

