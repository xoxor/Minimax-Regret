% IJCAI-21 Author's response

% Template file with author's reponse

\documentclass{article}
\pdfpagewidth=8.5in
\pdfpageheight=11in
\usepackage{ijcai21-authors-response}


\usepackage{times}
\usepackage{soul}
\usepackage{url}
\usepackage[hidelinks]{hyperref}
\usepackage[utf8]{inputenc}
\usepackage[small]{caption}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{booktabs}
\usepackage{algorithm}
\usepackage{algorithmic}
\usepackage{lipsum}
\urlstyle{same}

\newtheorem{example}{Example}
\newtheorem{theorem}{Theorem}


\begin{document}
\paragraph{Rebuttal to Reviewer $\#$2: factual error}
One of the weaknesses of the paper is indeed the fact that the method proposed here is not compared with others, neither in terms of computational efficiency, nor in terms of quality of the result. Only variants of the same methods are compared with each others

We believe it is erroneous to consider the lack of comparison a weakness. The simultaneous elicitation of both the voting rule and the agents preferences is a novel setting. To the best of our knowledge, there is no clear competitor from the state-of-the-art to compare with. However, please note that we designed all the strategies to challenge one another; in particular:
The Elitist Strategy has a very different approach than the Pessimistic Strategy to the point that it cannot be considered a variant. We compared these two strategies in a situation specifically tailored to advantage the Elitist Strategy.
The Experiment involving the Two Phases Strategy was designed to challenge our interleaving approach by comparing it with a more classical linear method: first elicit the rule and then the agent’s preferences or vice versa. The former coincides with the case of preferences elicitation, given the voting rule, investigated by Lu and Boutilier [2011].
We are not aware of any work that elicits the voting rule we could compare with —the work by Cailloux and Endriss [2014] does not consider scoring rules.

R2: “If an election is to be achieved, the voting rule has to be defined independently of the preferences of the voters. And probably not by the chairperson who may influence the result by choosing the weights.”
It is not true that any decision process involving preference aggregation requires a voting rule defined beforehand, nor that it is necessarily a bad idea to let a chair decide on the voting rule or influence the voting rule definition. The interest of considering incomplete knowledge in the voting rule has been advocated in a recent survey paper of a leading researchers in computational social choice [Lang 2020; section 2.5]. Jerôme’s paper also says that. HAH. The case of IJCAI aggregation process of reviews illustrates the point. The Introduction section of our article provides another example.

[Lang 2020] Jérôme Lang: Collective Decision Making under Incomplete Knowledge: Possible and Necessary Solutions. IJCAI 2020: 4885-4891

\paragraph{Rebuttal to Reviewer $\#$32: specific questions}
[If we have space we add that although the reviewer didn’t use the proper section, the questions were in the form provided in the FAQ “When to answer?”]

-Why would voters participate in a voting rule that is not public or common knowledge?
-I struggle to understand why a "third party elicits both votes and chair" setting might arise in practice. Can the authors give an example?
-Why is this easier than reflecting on the relative weights?
-If the chair can compute winners over and over for every elicitation for arbitrary size profiles, why wouldn't the chair just compute the real winner himself or herself, rather the delegate to the third party?

Other than the example we provided in the Introduction —that describes the hiring process of a new employee— we could consider the reviewing process of a conference where the best paper must be elected. This new example also responds to the concern regarding the lack of knowledge of the voting rule among the agents. In this context, the agents express their preferences on the papers they reviewed, but they are not aware of the voting rule the SPC member will apply when aggregating all the preferences. Nonetheless, reviewers are still willing to participate in the process. On the other hand, the SPC member may not have a specific voting rule in mind, and she will find it hard to provide a precise scoring vector if asked. This part addresses the argument on the relative weights. Imagine, for the sake of the example, that all the reviewers review all the papers and they rank them according to their preferences. How does the SPC select the best paper? Surely she could adopt the Borda count and pick the paper with the highest score, but this is not the most appealing method. Maybe the SPC strongly believes that being ranked once in the first position is “much more” valuable than being ranked two times second, but does not know exactly how much more (though she can judge example cases). This is similar to how the paper WeBuildAI (and the general literature in micro-economy) supposes that participants are able to compare pairs of matches, but does not assume that participants can explicit their utility functions. Specifying general algorithms is demanding, hence, we adapt a mechanism used in a real life experiment by Giritligil et al. [2005] in a novel way for the setting of elicitation of positioning scoring rules (PSRs). 

There is also an important methodological argument for being able to phrase questions in terms of winners out of profiles. This is arguably the most fundamental and natural view of what a social choice function is: it chooses winners out of profiles. The rest, such as talking in terms of weights, is a synthetic, constructed, view about how a social choice function works. Different such constructions could lead to different appreciations and judgements by participants. For example, PSRs can also be described in terms of distance to ideal profiles ( On the role of distances in defining voting rules, E Elkind, P Faliszewski, AM Slinko, AAMAS 2010). There is no a priori reason to believe that questioning the chair in terms of this different parametric space would yield logically equivalent answers: research in experimental psychology shows that participants’ answers differ widely when changing the phrasing of preference-related questions (Lichtenstein, Slovic - The Construction of Preference, Cambridge University Press, 2006). To get out of such conundrums, we need a language considered “fundamental”. Questions of the form “In this profile, who should win?” arguably provides such a natural language.

Finally, the chair could delegate to a third party, by agreeing to let the principle of “min-max regret” decide instead of picking her favorite winner, for example, because the chair wants to satisfy a form of fairness which she thinks that algorithm satisfies. This is a classical assumption in political science. Note that the chair cannot compute the real winner as she ignores the profile. 

-Is Figure 1 for the synthetic data? Please specify. Same question for Tables 2 and 3. In Figure 2, are the m=N,n=N lines the synthetic data?
-Why is Figure 2 shown for only Pessimistic, not all the approaches? Were all approaches tested on all data sets? Or were all approaches only tested on synthetic data?

Yes, when we do not specify the name of the dataset we mean data generated following the procedure described in Sec 5. Regarding the real datasets, we only tested the Pessimistic strategy for the following reasons:
Random was considered only as a baseline in the first experiment, which shows that Pessimistic performs much better; therefore we did not consider Random any further. 
Extended Pessimistic is computationally too consuming and it can be tested only on small instances; as explained in “Sec 4 - Elicitation strategies”; 
Elitist was designed with the only purpose of challenging our best strategy (Pessimistic) in extreme cases tailored to favor the Elitist. Testing this strategy in other settings does not yield interesting information;
Two Phase was designed to compare our interleaving approach to a more classical linear method: first elicit the rule and then the agents preferences or vice versa. We thought that the most challenging situation (Impartial Culture) was the best way to perform this test.



\paragraph{Rebuttal to Reviewer $\#$56: specific questions}

They seem to have a linear constraint question in mind which they then convert to a “what is the winner of this profile?” question. However I think the opposite may be more plausible. Having a profile for which you want to know the winner and then deduce the constraint.
-Can you clarify better the rationale behind the assumptions you make on questions to the chair?

PAOLO DRAFT: Indeed the question is asked by showing a profile and asking who should win; the response is encoded as a constraint and added to the system’s knowledge. Note that we want to ask an informative query: the elicitation strategy decides which question to be asked, and, if it is of the “chair” type, the strategy decides the linear constraint to check; this is then translated to a profile.

The usefulness in practice is not really clear. If the chair does not know the weight vector, he can’t answer the questions.
-You say that you assume the chair to be human, yet you think he will answer hundreds of questions..? Could you elaborate more on why you think this is reasonable?
Maybe the chair could be instead a black box PSR that let’s you test it for different outcomes…

PAOLO DRAFT: We assume the chair to be human and, as discussed in the paragraph “Building concrete questions for the chair“ on page 3, we view questions “what is the winner of this profile” to be easier to answer than directly asking the weights (in the same way as, for the problem of elicitation an utility function, one would ask comparison queries rather than asking directly utility values). 
Note that, in our experiments, we often plot the total number of questions in order to have a simple way to compare the total elicitation cost. But it is important to note,  queries are posed to different agents and to the chair, and that the number of questions each has to answer is usually not that big. In fact the number of questions asked to the chair using the Pessimistic strategy (as shown in the appendix) is often quite small  (e.g. zero in skate and "courses", 8.4 in m5n10, 13 in m5n20, 30 in tshirt,...), this is because the strategy does a good job of asking the question that gives more information, and often only “sparse” information about the voting rule is enough. Similarly, the average number of questions asked to a voter is also reasonable (e.g questions per agent 6.5 in courses, 6.1 in m5n10,  )
: X.X in Experiment YY, for instance. In Table 2, the (10,20) example shows that to reach a “low” regret -that we define as n/10- we need to ask 340 questions. This number should be divided among the voters and the chair, resulting in ~ 10 questions per voter, which we consider a reasonable amount. The fact that asking too many questions to the chair is not worth it isworth is also displayed in Table 3 in the main text.
Finally, note that the process could be terminated early: e.g. one could decide to stop after a fixed number of questions (even if regret is not zero) and to output as an “approximate winner” the alternative with lowest minimax regret value.
If the paper is accepted, we’ll stress the points above and include in the final version the Table with $\#$questions from the appendix.

\end{document}

