\RequirePackage[l2tabu, orthodox]{nag}
\documentclass[version=3.21, pagesize, twoside=off, bibliography=totoc, DIV=calc, fontsize=12pt, a4paper]{scrartcl}
\input{preamble/packages}
\input{preamble/redac}
\input{preamble/math_basics}
\input{preamble/math_mine}
\usepackage{pdfpages}

%I find these settings useful in draft mode. Should be removed for final versions.
	%Which line breaks are chosen: accept worse lines, therefore reducing risk of overfull lines. Default = 200.
		\tolerance=2000
	%Accept overfull hbox up to...
		\hfuzz=2cm
	%Reduces verbosity about the bad line breaks.
		\hbadness 5000
	%Reduces verbosity about the underful vboxes.
		\vbadness=1300

\title{Resubmission: Simultaneous Elicitation of Scoring Rule and Agent Preferences for Robust Winner Determination}
\author{Submission ID: 554, AAMAS-2021}
\date{}
\hypersetup{
	pdfsubject={Cover letter},
	pdfkeywords={elicitation},
}

\begin{document}
\maketitle

\begin{abstract}
Social choice deals with the problem of determining a consensus choice from the preferences of different agents.
In the classical setting, the voting rule is fixed beforehand and full information concerning the preferences of the agents is provided.
This assumption of full preference information has recently been questioned by a number of researchers and
	several methods for eliciting the preferences of the agents have been proposed.
	%  are completely known have been proposed, as well as techniques that consider the opposite scenario. 

In this paper we argue that in many situations one should consider as well the voting rule to be 	partially specified.
%	This article goes one step further by tackling one important new case, namely, when both the voting rule and the agents preferences are partially known. It also permits to obtain a progressively refined recommendation without requiring to achieve full knowledge of either sort of information.
%This is useful because providing such information is often costly: the chair may find it hard to specify a rule completely; agents may need time to form reflective preferences.	
	Focusing on positional scoring rules, we assume that the chair, while not able to give a precise definition of the rule, is capable of answering simple questions requiring to pick a winner from a specific example profile. In addition, we assume that the agent preferences have to be elicited as well and are acquired by asking comparison queries. 
	We propose a method for robust approximate winner determination and interactive elicitation based on minimax regret; we develop several strategies for choosing the questions to ask to  the chair and the agents in order to %acquire the most relevant information for
converge quickly to a near-optimal alternative. Finally, we analyze these strategies in experiments %in order to validate our approach
 %focusing on settings 
 where the voting rule and the preferences are simultaneously elicited.
 %and obtain practical guidelines.
\end{abstract}

\section{Cover Letter}
\input{cover_letter.tex}

\section{Reviews AAMAS-2021}
\input{reviews_aamas.tex}

\subsection{Our rebuttal}
Our proposal is methodologically innovative: it addresses in a new way the difficult problem of eliciting preferences about voting rules. It opens up a novel path to gather and exploit preferential information about voting rules, in parallel with more classical preferential information about the alternatives under scrutiny. As a result, multiple challenging research questions open up, several of which are raised by the reviewers. We warmly thank them for these observations.

As reviewer 1 points out, one could simply ask for direct information about the parameters of the rules, such as the weight vector. But it is unclear whether the answers to such questions would be meaningful. For example, in many cases, the chair (supposed to be human) may not know whether the largest weight should be twice, or three times, the weight associated with the second rank.

We ask the chair which alternative should win given a concrete profile. Such questions have precise semantics whose understanding is shared by the chair. This way of asking questions is sufficiently natural that it has been used in experimental settings investigating the feeling of justice of individuals (Does majoritarian approval matter in selecting a social choice rule? An exploratory panel study, Ebru Giritligil and Sertel, Social Choice and Welfare 25(1):43-73, 2005). To the best of our knowledge, the use of such questions to systematically guide an elicitation process is novel. We will highlight this aspect in the paper.

Our approach is analogous to that of decision theorists with preference elicitation: a large stream of research considers more meaningful to ask direct choice questions ("please choose either a or b") than to question the decision maker about the shape of its utility function. The former are considered "observable": acts of choice are translated to preference statements.

Concerning the hypothesis of convexity raised by reviewer 1, we need to assume that we look for a function inside a specific class of functions (here, the scoring rules with convex weights) because the class of all possible functions is too large. This allows for mixing an axiomatic basis with more precise "observable" questions; again, as it is usually done in decision theory (which often assumes the Subjective Expected Utility axioms). The use of convex weights is a natural and common assumption: losing ranks at the top of the ranking is more damaging than losing ranks at the bottom.

A concrete application of our work might be a committee that is about to hire a new employee, whose performances are evaluated by several experts. The members of the committee may not have a voting rule in mind at the start of the process, and might not wish to agree on a specific voting rule, but they might be willing to answer enough questions about selecting winners out of specific profiles to determine their employee of choice.

Regarding the experimental concerns addressed by reviewer 1, our strategies and setting are meant to tackle small scale social choice situations such as just exemplified. Our questioning method, in particular, does not scale to hundreds of candidates because the chair must be assumed to have limited cognitive capacity.

IC is a quite challenging situation: as can be expected intuitively (and shown experimentally by Lu and Boutilier in their setting), the number of questions to be asked decrease with less varied profiles. We want to focus on the most critical setting, as there is a wide variety of possible situations to test in such experiments.

The reviewers are right to point out that our comments about Table 3 were overconfident, this will be corrected.

Reviewer 1 Question6 : We should have written “given to c the ranks 3 and m” instead of (3, m) in the proof of Claim 4.

Reviewer 2 Question2: The $\lambda$-range is initialized to [1,n] because $\lambda \geq1$ by convexity and we assume $\lambda \leq n$ wlog: for $\lambda \geq n$, the rule coincides with Plurality.

Regarding the guarantees concerns raised by reviewer 2: The general lack of theoretical guarantees with respect to the number of questions in the literature adopting minimax regret approaches suggest that obtaining such results is very difficult, if possible. However, our approach guarantees to return the true winners when the elicitation is completed. Note that the process can be terminated early, and offers a guaranteed bound on the regret at any time.

Reviewer 2 Question1: At the start of the elicitation, the space of uncertainty is so large that the adversary can attain the maximum possible value of regret; multiple answers are needed to constrain her enough for the MMR to start decreasing. When approaching optimality, the pace of MMR reduction decreases.

Reviewer 3 Question1: We did not investigate a systematic way of mixing strategies but we manually mixed different ideas in order to obtain the strategies we presented. For example Two phase and Extended Pessimistic reuse ideas present in the Pessimistic strategy.

\section{Reviews IJCAI-20}
\input{reviews_ijcai.tex}

\section{Rejected paper AAMAS-2021}
%\includepdf[pages=-]{aamas21_paper_554.pdf}

%\bibliography{bibl}

\end{document}

