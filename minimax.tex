\documentclass{article}
\pdfpagewidth=8.5in
\pdfpageheight=11in
% The file ijcai21.sty is NOT the same than previous years'
\usepackage{ijcai21}
\usepackage{times}
\usepackage{soul}
\usepackage{amsthm}
\usepackage[hidelinks]{hyperref}

%%% Load required packages here (note that many are included already).
\input{preamble/packages}
\input{preamble/math}
%for appendix
\usepackage{import}
\usepackage{algorithm, algpseudocode}
\usepackage{booktabs}
\usepackage{pgfplots}
\pgfplotsset{compat=1.16}

\newcommand{\commentOC}[1]{\textcolor{blue}{\small$\big[$OC: #1$\big]$}}
\newcommand{\commentBN}[1]{\textcolor{red}{\small$\big[$BN: #1$\big]$}}

\pdfinfo{
	/TemplateVersion (IJCAI.2021.0)
}


%I find these settings useful in draft mode. Should be removed for final versions.
	%Which line breaks are chosen: accept worse lines, therefore reducing risk of overfull lines. Default = 200.
		\tolerance=2000
	%Accept overfull hbox up to...
		\hfuzz=2cm
	%Reduces verbosity about the bad line breaks.
		\hbadness 5000
	%Reduces verbosity about the underful vboxes.
		\vbadness=6000

%%% Use this command to specify the title of your paper.

\title{Simultaneous Elicitation of Scoring Rule and Agent Preferences for Robust Winner Determination}

%%% Provide names, affiliations, and email addresses for all authors.

\author{ID: 3177}

%\author{
%	Beatrice Napolitano$^1$\footnote{Contact Author}\and
%	Olivier Cailloux$^1$\and
%	Paolo Viappiani$^2$\\
%	\affiliations
%	$^1$Université Paris-Dauphine, Université PSL, CNRS, LAMSADE\\
%	$^2$LIP6, UMR 7606, CNRS and Sorbonne Universit\'e\\
%	\emails
%	\{beatrice.napolitano, olivier.cailloux\}@dauphine.fr,
%	paolo.viappiani@lip6.fr
%}

         
\newcommand{\BibTeX}{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em\TeX}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{document}

\maketitle 

\begin{abstract}
Social choice deals with the problem of determining a consensus choice from the preferences of different agents.
In the classical setting, the voting rule is fixed beforehand and full information concerning the preferences of the agents is provided.
This assumption of full preference information has recently been questioned by a number of researchers and
	several methods for eliciting the preferences of the agents have been proposed.
	%  are completely known have been proposed, as well as techniques that consider the opposite scenario. 

In this paper we argue that in many situations one should consider as well the voting rule to be 	partially specified.
%	This article goes one step further by tackling one important new case, namely, when both the voting rule and the agents preferences are partially known. It also permits to obtain a progressively refined recommendation without requiring to achieve full knowledge of either sort of information.
%This is useful because providing such information is often costly: the chair may find it hard to specify a rule completely; agents may need time to form reflective preferences.	
	Focusing on positional scoring rules, we assume that the chair, while not able to give a precise definition of the rule, is capable of answering simple questions requiring to pick a winner from a concrete profile. In addition, we assume that the agent preferences also have to be elicited. %and are acquired by asking comparison queries. 
	We propose a method for robust approximate winner determination and interactive elicitation based on minimax regret; we develop several strategies for choosing the questions to ask to  the chair and the agents in order to %acquire the most relevant information for
converge quickly to a near-optimal alternative. Finally, we analyze these strategies in experiments %in order to validate our approach
 %focusing on settings 
 where the  rule and the preferences are simultaneously elicited.
 %and obtain practical guidelines.
\end{abstract}

\section{Introduction}
Aggregation of preference information is a central task in many computer systems (recommender systems, search engines, etc).
In many situations, such as in group recommender systems, the goal is to find a consensus choice;
%It is therefore natural to look at methods from social choice and see how they can be adapted for group decision-making in a computerized setting.
social choice theory can provide foundations for such applications. %Methods from social choice can be adapted for group decision-making in a computerized setting.

The traditional approach to social choice assumes that both the social choice function and the full preference orderings of the agents (voters) are expressed beforehand. These represent two strong hypothesis.
Requiring agents to express full preference orderings can be prohibitively costly (in terms of cognitive and communication cost).
This observation has motivated a number of recent works considering social choice with partial preference orders and incremental elicitation of agent preferences. 

Furthermore, it is often difficult for non-expert users to formalize a voting rule on the basis of some generic preferences over a desired aggregation method. Thus, the first hypothesis should also be relaxed. 
Consider, as an example, a committee that is about to hire a new employee, whose performances are evaluated by several experts. The members of the committee may not have a voting rule in mind at the start of the process, and might not wish to agree on a specific voting rule, but they might be willing to answer a few questions requiring to select who should be the winner out of specific profiles. 
%The information provided can be used to   % to determine their employee of choice.

%This paper considers both sources of uncertainty at the same time, and proposes a method able to recommend a consensus choice without requiring full knowledge of either.
In this paper we focus on positional scoring rules, that are a particularly common method used to aggregate rankings, and we assume that both the agent preferences and the social choice rule are partially specified. 
We develop methods, based on the notion of minimax regret, for determining a robust ``winner'' under uncertainty of both the voting rule and the agent preferences.
%alternative using positional scoring rules and 
We provide incremental elicitation methods that 
at each step of the elicitation ask a question either to one of the agents or to the chair (the person or organization supervising the voting process) and discuss several heuristics that determine queries that quickly reduce regret. 
Answers to questions are encoded in terms of constraints; questions to the agents are comparions between pairs of alternatives while
questions to the chair ask  to select who should be the winner in a synthetic profile.
While previous works have considered either partial information about the agent preferences or a partially specified aggregation method, we do not know of any work considering both sources of uncertainty at the same time.
Actually, very few works altogether have considered the problem of eliciting a voting rule by asking questions to the chair.

Our approach is evaluated experimentally in simulations where the both the voting rule and the agent's preferences are initially unknown to the system and incrementally revealed by answering questions.
We compare the effectiveness of several strategies  including strategies that proceed in phases, learning first as much as possible about the voting rule and then focus on eliciting agent's preferences, and as well strategies that interwind questions to chair and to the agents based on which is estimated to provide more information.
%Our approach permits to compare experimentally strategies that question the chair, the agents, or both.

%A concrete application of our work might be a committee that is about to hire a new employee, whose performances are evaluated by several experts. The members of the committee may not have a voting rule in mind at the start of the process, and might not wish to agree on a specific voting rule, but they might be willing to answer enough questions about selecting winners out of specific profiles to determine their employee of choice.

%We describe informally here a few of the conclusions stemming from these experiments, given a problem involving $m$ alternatives and $n$ agents. First, a good quality recommendation can be reached by asking what can be considered a reasonable number of questions to the chair and agents. For example, in a problem of size $m = 5$, $n = 10$, only $55$ questions in total are required to reach a good quality recommendation, which can be considered reasonable as these questions are to be dispatched over $10$ agents and the chair.
%Second, the quality of the recommendation increases faster than linearly with the number of questions,  after an initial phase with almost no increase in quality, before slowing down and converging to an optimal recommendation. 
%Third, we experimentally find out that asking questions only to the agents performs similarly to asking questions both to the agents and the chair, although questions to the chair do have a positive value in terms of quality of the recommendation.
%Knowing this permits to choose the questioning strategy wisely depending on the estimated cost of each kind of question, which depends on the application. 

%NOTE: the structure of the article is perhaps self evident...
%The paper is organized as follows. \Cref{sec:related} reviews the works related to our objective and
%\Cref{sec:background} provides the necessary background. In \cref{sec:mmr} we provide a method for robust winner determination using the minimax criterion. %, a method that selects a winner that minimizes the worst possible regret.
%In Section \ref{sec:elicit} we provide an interactive elicitation protocol based on minimal regret;  Section \ref{sec:experiments} presents an experimental validation of our approach and some guidelines stemming from these simulations; and Section \ref{sec:conclusions} provides some final thoughts.

\paragraph{Related Work}
\label{sec:related}
In the context of social choice, several authors have been interested in obtaining information about winners with reduced assumptions about the knowledge of the agent preferences (assuming that the voting rule is known). One early work is  by \Citet{Conitzer2005} who studied the complexity of communication, using different voting rules; %determining lower and upper bounds;
%they showed that, 
in the worst case, the agents should send their complete set of preference for several rules. 
\Citet{Konczak05} studied the computation of possible and necessary winners in the case of partial knowledge of agent preferences, for various voting rules; %and showed that the problem is hard in the general case.
\citet{Xia2008} then showed that, while the identification of a necessary co-winner in scoring rules is polynomial,  the determination of possible co-winners is NP-hard; they also  proposed polynomial-time algorithms when using maximin and Bucklin.
\citep{Walsh2007} showed that the general case remains computationally hard even when restricting to single-peaked preferences \citep{Walsh2007};  sufficient conditions that ensure tractability were then found \citep{Pini2007}.


Since in many practical situations there would be too many possible winners but no necessary winners, %several authors proposed elicitation methods of agent preferences. 
several works addressed the problem of  elicitation of agent preferences \citep{Naamani-Dery2015,Kalech2011,Lu2011,Pini2009,Benabbou2016,Dey2016,Dey2016_2}  using a variety of approaches (minimax regret, Bayesian methods, etc.), with the goal of converging to a necessary winners; \citep{Walsh2009,Conitzer2009}  analyzed when to stop the elicitation process.

While most of the focus in the research community has been in dealing with incomplete agent preferences, 
another line of research \citep{Stein1994,Llamazares2013,Viappiani2018} has dealt with %scenarios where it is instead the voting rule that is partially defined. % but the preferences are given. 
a  partially defined voting rule.
%A classic paper is the one by \citet{Stein1994} that, considering scoring rules, identified dominance relations between alternatives; these relations allow to determine pairs of alternatives where the first is at least as good as the second no matter which weights are chosen among a generic class of weights (decreasing weighs or convex decreasing weights).
%More recent articles considered the problem of dealing with unspecified weights in positional scoring rules: \citet{Llamazares2013} proposed a method based on Data Envelopment Analysis (DEA), while \citet{Viappiani2018} proposed to aggregate the uncertainty in weights using criteria used in decision-making under uncertainty (such as minimax regret). 
\Citet{Cailloux2014} provided an elicitation framework for a different class of rules.

Finally, we mention works addressing the manipulability of voting rules \citep{Elkind2012,Dey2018,Dey2018_2,Conitzer2011,Baumeister2019}, and studies of strategic behaviors
% when agents learn incrementally about other agent preferences
 \citep{Endriss2016,Lev2019,Annemieke2012}.

\section{Social choice with partial information}
\label{sec:background}
We now introduce some basic concepts.
We consider a set $A$ of $m$ alternatives (products, restaurants, movies, public projects, job candidates, etc.) and a set $\set{1, …, n}$ of agents. Each agent $j$ comes from an infinite set $\N$ of potential agents and is associated to her “real” preference order ${\pref_j}  \in \linors$ which is a linear order (a connected, transitive, asymmetric relation) over the alternatives.
Following the social choice nomenclature, we call {\em profile} the association of a preference to each agent, considering a subset of agents from the set $\N$, and denote a profile by $(\pref_1,\ldots,\pref_n)$.
A profile is equivalently represented by $\profile=(v_1,\ldots,v_n)$ where $v_j(i) \in \set{1, \ldots, m}$ denotes the rank (position) of alternative $i$ in the preference order $\pref_j$. 

Let $V$ be the set of possible preference profiles (the union, for any integer $n$, of the $n$-fold Cartesian product of the linear orders over the alternatives).
A social choice function $f : V \rightarrow \powersetz{A}$ associates a profile with a set of winners, where $\powersetz{A}$ represents the set of subsets of $A$ except for the empty set (sets are used for tied winners).
Among the many possible social choice functions, we consider {\em positional scoring rules (PSR)}, which attach weights to positions according to the vector $(w_1, \ldots, w_m)$, also known as the {\em scoring vector}.
An alternative obtains a score that depends on the rank obtained in each of the preference orders:
\begin{align}
	\label{eq:srule}
	s(x; \profile, \w) = \sum_{j=1}^{n} w_{v_j(x)}
	= \sum_{r=1}^{m} \alpha^{x}_r w_r 
\end{align}
where $\alpha^{x}_r$ is the number of times that alternative $x$ was ranked in the $r$-th position.
The winners are the alternatives with the highest score.

In this work we assume fixed, but unknown to us, a profile $\profile^*$ representing the preferences $\pref_j^*$ of the agents, and a weight vector $\w^*$, representing the preferences of the chair. We want to reason about partial preference information concerning those objects.
At a given time, our knowledge of agent $j$'s preference is encoded by a partial order over the alternatives, thus a transitive and asymmetric binary relation, denoted by $\ppref_j$. 
In this work we assume that preference information is truthful, i.e. $a \ppref_j b ⇒ a \pref_j^* b$.
%We use $\prefinc$ to denote incomparability, that is $a \prefinc_{j} b$ iff $a \nppref_j b \wedge b \nppref_j a$.
An incomplete profile $\pprofile = (\ppref_1, \ldots, \ppref_n)$ maps each agent to a partial preference.

A completion of $\ppref_j$ is any linear order $\pref$ that extends $\ppref_j$ and we indicate with $C(\ppref_j) = \set{{\succ} \in \linors \suchthat {\ppref_j} \subseteq {\succ}}$ the set of possible completions of $\ppref_i$.
Then $C(\pprofile)=C(\ppref_1)\times … \times C(\ppref_n)$ is the set of complete profiles extending $p$. Note that $\profile^* \in C(\pprofile)$.

We also assume that the weights of the scoring rule are only partially specified.
Therefore, the vector $(w_1,\ldots,w_m)$  is not known but we are given a set of constraints restraining the possible values that weights can take.
We consider a decreasing sequence of weights:
\begin{align}
	1=w_{1} ≥ w_{2} ≥ \ldots ≥ w_{m}=0. \label{eq:monotone}
\end{align}
This is a natural assumption, as it is better to be ranked first than second, second than third, etc. 
Without loss of generality, we consider that $w_1=1$ and $w_m=0$. 

The weights of a scoring rule can model different preferences of the chair. 
For instance, the weights can control the inclination to favor ``extreme'' alternatives (often at either the top or the bottom of the input rankings) at the expenses of ``moderate'' alternatives (that are more consistently in the middle part of the input rankings). 

An important class of scoring rule is the one composed of weights that represent a convex sequence \citep{Stein1994,Llamazares2016}, meaning that the difference between the weight of the first position and the weight of the second position is at least as large as the difference between the weights of the second and third positions, etc.
\begin{equation} 
	\label{eq:convexity}
	\forall r \in \{1,\ldots,m-2\}: w_r - w_{r+1} \geq w_{r+1}-w_{r+2}.
\end{equation}
The constraint above is often used when aggregating rankings in sport competitions.
We use $\W$ to denote the set of convex weight vectors. It is also a natural and common assumption: losing ranks at the top of the ranking is more damaging than losing ranks at the bottom.

In general it can be difficult to set the weights in an appropriate way.
We assume that, in addition of basic requirements (monotonicity and convexity), the chair is able to specify additional preferences about how the social choice function should behave.
In this work we assume that the preferences of the chair are encoded with linear constraints about the vector $\w$, relating the value of the weights of different positions, and the set of these constraints is denoted by $\Co_W$. Moreover, we use $\pw \subseteq \W$ to denote the set of weight vectors compatible with the preferences expressed by the chair about the scoring vector.
Of course it may be difficult for real decision makers to state preferences about the voting rule in such an abstract way.
We will show in \cref{sec:elicit} that the additional preferences we use can be elicited by 
%asking questions about concrete profiles, for instance, by 
showing a complete profile of a small synthetic election and asking who should be elected in this case.

\section{Robust winner determination}
\label{sec:mmr}
In this paper, we consider a setting where both the agent preferences and the preferences of the chair about the voting rule are incomplete.
As reviewed in \cref{sec:related}, some authors have considered possible and necessary winners assuming 
either a partial profile or assuming an incompletely specified scoring rule.

Notice that often there are no necessary winners and too many possible winners; it is therefore useful to declare a winner given partial information.
As a decision criterion to determine a winner, we propose to use minimax regret. 
Minimax regret \citep{Savage1954} is a decision criterion that has been used for robust optimization under data uncertainty \citep{Kouvelis1997} as well as in decision-making with uncertain utility values \citep{Salo2001,Boutilier2006}.
In particular, \citet{Lu2011} have adopted minimax regret for winner determination in social choice where
the preferences of agents that are only partially known, while the social choice function is predetermined and known.

In this work, we consider the simultaneous presence of uncertainty in agent preferences and in the weights of the scoring rule used as a social choice function.
Using {\em maximum regret} to quantify the worst-case error, the alternatives that minimize this error are selected as tied winners, providing us with a form of robust optimization.
Intuitively, the quality of a proposed alternative $a$ is how far $a$ is from the optimal one in the worst case, given the current knowledge.

The maximum regret is considered by assuming that an adversary can both 1) extend the partial profile $\pprofile$ into a complete profile, and 2) instantiate the weights choosing among any weight vector in $\pw$, where $\pprofile$ and $\pw$ represent our knowledge so far.
We formalize the notion of minimax regret in multiple steps.
First of all, $\Regret(x, \profile, \w)$ is the “regret” of selecting $x$ as a winner instead of choosing the optimal alternative under $\profile$ and $\w$:
\begin{align} 
	\Regret(x; \profile, \w) = \max_{y \in A} s(y; \profile,\w) - s(x; \profile, \w).
\end{align}
The pairwise maximum regret $\PMR(x,y;\pprofile,W)$ of $x$ relative to $y$ given the partial profile $\pprofile$ and the set of weights $W$
is the worst-case loss of choosing $x$ instead of $y$ under all possible realizations of the full profile {\em and} all possible instantiations of the weights:
\begin{align}
	\PMR(x,y; \pprofile, W) & = \max_{\w \in W} \max_{\profile \in C(\pprofile)} s(y; \profile,\w) - s(x; \profile,\w).
\end{align}

The maximum regret $\MaxR(x;\pprofile,W)$ is the worst-case loss of $x$. That is the loss occurred as the result of an adversarial selection of the complete profile $\profile \in C(\pprofile)$ and of the scoring vector $\w \in W$ that together maximize the loss between $x$ and the true winner under $\profile$ and $\w$:
\begin{align}
	\MaxR(x; \pprofile, W) & = \max_{y \in A} \PMR(x,y; \pprofile, W)\\
	& = \max_{\w \in W} \max_{\profile \in C(\profile)} \Regret(x; \profile, \w).
\end{align}

Finally,  $\MMR(\pprofile,W)$ is the value of minimax regret under $\pprofile$ and $W$, obtained when recommending a minimax optimal alternative $x^*_{\pprofile, W} \in A^*_{\pprofile, W}$:

\begin{align}
	\MMR(\pprofile,W) & = \min_{x \in A} \MaxR(x;\pprofile,W); \\
	A^*_{\pprofile, W} & = \argmin_{x \in A} \MaxR(x;\pprofile,W).
\end{align}
By picking as consensus choice
an alternative associated with minimax regret, we can provide a recommendation that gives worst-case guarantees, giving some robustness in face of uncertainty (due to both not knowing the agent preferences and the weights used in the aggregation). 
In cases of ties in minimax regret, we can either decide to return all minimax alternatives $A^*_{\pprofile, W}$ as winners or to pick just one of them using some tie-breaking strategy.

Observe that if $\MMR(\pprofile, W)\!=\!0$, then any $x^{*}_{\pprofile,W} \in A^*_{\pprofile, W}$ is a necessary co-winner; this means that for any valid completion of the profile and any feasible $w \in W$, $x^{*}_{\pprofile,W}$ obtains the highest score.

We note that our notion of regret gives some cardinal meaning to the scores: instead of just being used to select winners under the corresponding PSR, their differences are considered as representing the regret of the chair.

% Add some general remarks about using minimax regret

\paragraph{Computation of minimax regret}
In order to compute pairwise maximum regret, and therefore minimax regret, we decompose the $\PMR$ into the contributions associated to each agent by adapting the reasoning from \citet{Lu2011}.
The setting is however more challenging due to the presence of uncertainty in the weights.

Recall that, in the computation of $s(x; \profile, \w)$, $w_{v_j(x)}$ represents the score that $x$ obtains in the ranking $v_j$ (see \cref{eq:srule}).
Since scoring rules are additively decomposable, we can consider separately the contribution of each agent to the total score. Thus, we can write the actual regret of choosing $x$ instead of $y$ as
\[
s(y; \profile,\w) - s(x; \profile, \w) = \sum_{j=1}^n w_{v_j(y)} - w_{v_j(x)},
\]
and we can rewrite $\PMR$ as follows:
\begin{align}
	& \PMR(x,y; \pprofile, W) = \max_{\w \in W} \max_{\profile \in C(\pprofile)} [ s(y; \profile,\w) - s(x; \profile,\w) ] \\
	& =  \max_{\w \in W} \sum_{j=1}^{n} \max_{v_j \in C(\succ_j^p)} [w_{v_j(y)} - w_{v_j(x)}]. \\
\end{align}
Note that in general the inner max depends on the weights chosen by the outer max.

We are interested in computing $\PMR(x, y; \pprofile, W)$. This represents the “worst” difference of score, thus the difference of score between $y$ and $x$ under the worst case preferences compatible with $\pprofile$ and $W$, where the worst case is the one that maximizes this difference of score.
We consider now a procedure for completing a partial profile that was first proposed by \citet{Lu2011} when considering %minimax regret with 
a fixed weight vector.
As we will show, this procedure can also be used when the weight vector is not completely known. Let us write $a \pprefeq_j b$ iff $a \ppref_j b \lor a = b$.

\begin{proposition} \label{claim:completion}
	There exists a completion $\hat{\profile} \in C(\pprofile)$ of the profile $\profile$ such that $\PMR(x,y; \pprofile, W) = \max_{\w \in W} [ s(y; \hat{\profile}, \w) - s(x; \hat{\profile}, \w) ]$ and such that the linear order $\hat{v}_{j}$ of each agent $j$ satisfies:
	\begin{align} 
		\label{eq:complx}
		a \pref_j x &⇔ ¬(x \pprefeq_j a)\\
		\label{eq:comply}
		y \pref_j a &⇔ ¬(a \pprefeq_j y) ∧ ¬((x \pprefeq_j y) ∧ ¬(x \pprefeq_j a)).
	\end{align} 
\end{proposition}

Let ${\pprefeq_j}(x)$ designate the set of alternatives known to be considered by $j$ as less good than or equal to $x$, and ${\pprefinv_j}(y)$ be the set of alternatives known to be considered by $j$ as strictly better than $y$.
\begin{proposition} \label{claim:rankPMR}
	The rank of $x$ in the PMR-maximizing linear orders of agent $j$ is $\hat{v}_{j}(x) = 1+\card{A}-\card{{\pprefeq_j}(x)}$, and the rank of $y$ is $\hat{v}_{j}(y)=1+\card{{\pprefinv_j}(y)}+\card{\beta}$, where $\card{\beta} = \card{A \setminus ({\pprefeq_j}(x) \cup {\pprefinv_j}(y))}$ if $(x \pprefeq_j y)$ and $\card{\beta} = 0$ otherwise.
\end{proposition}

The proposition can also be understood by observing that in the case $(x \pprefeq_j y)$, $\beta$ is the number of alternatives incomparable with both $x$ and $y$.
\begin{proposition}
	The $\PMR$ can be written as:
	\begin{align} 
		\PMR(x,y; \pprofile, W)  
		& = \max_{w \in W} \sum_{j=1}^n w_{\hat{v}_j(y)} - w_{\hat{v}_j(x)} \\ 
		& = \max_{w \in W} \sum_{r=1}^m (\hat{\alpha}_{r}^{y} - \hat{\alpha}_{r}^{x}) w_i. 
	\end{align}
	where $\hat{\alpha}_{r}^{y}$ (resp. $\hat{\alpha}_{r}^{x}$)  is the number of times $y$ (resp. $x$) is at rank $r$ in the complete profile $\hat{\profile}$ as determined in \cref{claim:rankPMR}. %\ref{claim:completion}.
\end{proposition}
The last proposition shows that PMR is linear in the weights.
Recall that the preferences of the chair are encoded with linear constraints $\Co_{W}$.
The pairwise max regret $\PMR(x,y; \pprofile,W)$ can be obtained as the solution of the following linear program defined on the variables $w_1, …, w_m$, which represent the weights attached to different positions:
\begin{align}
	\max_{\w} & \sum_{r=1}^m (\hat{\alpha}_{r}^{y} - \hat{\alpha}_{r}^{x}) w_{r}\\
	\text{ s.t. } & \text{\cref{eq:monotone}} \text{ and } \text{\cref{eq:convexity}} \text{ and } \Co_W.
\end{align}
Note that given our choice $w_{1}=1$ and $w_{m}=0$, there are only $m-2$ variables 
(we leave $w_{1}$ and $w_{m}$ in the LP just for clarity of presentation).

The max regret $\MaxR(x; \pprofile, W)$ is determined by considering the pairwise regret of $x$ with all other alternatives in $A$.
Optimal alternatives w.r.t. minimax regret are the ones with least max regret. 
Observe that, whenever the $\PMR$ of an alternative $x$ (against some other alternative $y$) exceeds the best MR value found so far, we do not need to further evaluate $x$. 
This idea can be exploited further by adopting a minimax-search tree \citep{Braziunas2012}.

\section{Interactive Elicitation} 
\label{sec:elicit}
We propose an incremental elicitation method based on minimax regret.
At each step, the system may ask a question either to one of the agents about her preferences or to the chair about the voting rule. 
The goal is to obtain relevant information to reduce minimax regret as quickly as possible.
As termination condition of elicitation, we can check whether minimax regret is lower than a threshold; or after having asked a given number of questions.
%if we wish optimality, we can perform elicitation until minimax regret drops to zero.

The remainder of this section is structured as follows.
First, we discuss the different types of questions that can be asked to the agents and to the chair, and the way responses are handled.
Then, we describe different strategies to determine informative queries to ask next, with the goal of reducing $\MMR(\pprofile,W)$ quickly.

\paragraph{Question types}
We distinguish between questions asked to the agents and questions asked to the chair.
As {\em questions asked to the agents} it is natural to consider comparison queries asking to compare two alternatives.
%Another common type of queries are {\em top-k}, asking to each agent her $k$ most preferred alternatives.
The effect of a response to a question asked to an agent is the increase in our knowledge about the agent rankings, thus augmenting the partial profile $\pprofile$. 
If agent $j$ answers a comparison query stating that alternative $a$ is preferred to $b$, then the partial order $\ppref_j$ is augmented with $a \ppref_j b$ and by transitive closure.

A bit more discussion is needed about {\em questions asked to the chair}.
Such questions aim at refining our knowledge about the scoring rule; a response gives us a constraint on the weight vector $\w$.
In particular, we want to obtain constraints of the type
\begin{align}
	w_{r} - w_{r+1} \geq \lambda (w_{r+1} - w_{r+2})
\end{align}
for $r \in \{1,\ldots,m-2\}$, relating the difference between the importance of ranks $r$ and $r+1$ with the difference between ranks $r+1$ and $r+2$.

\paragraph{Building concrete questions for the chair}
As we assume that the weights constitute the utility components of the chair, it might be reasonable to assume that the chair is able to answer such abstract questions in our setting. However, it is important to make sure that a question can also, in principle, be asked in a more concrete way, in terms of winners of example profiles. This permits to test how the chair understands the question and to relate the preference of the chair to her choice behavior in the economic sense. 

Such questions have precise semantics whose understanding is shared by the chair. This way of asking questions is sufficiently natural that it has been used in experimental settings investigating the feeling of justice of individuals \citep{Giritligil2005}. To the best of our knowledge, the use of such questions to systematically guide an elicitation process is novel.

Our approach is analogous to that of decision theorists with preference elicitation: a large stream of research considers more meaningful to ask direct choice questions ("please choose either a or b") than to question the decision maker about the shape of its utility function. The former are considered "observable": acts of choice are translated to preference statements.

Furthermore this will be necessary for an ordinal extension of our work where the scores would not be considered as cardinal utilities.
Thus, our task is to build a profile, given $\lambda$ and $r ≤ m-2$, in such a way that the set of (tied) winners picked by the chair reveals whether $w_{r} - w_{r+1} \geq \lambda (w_{r+1} - w_{r+2})$.
\begin{proposition}\label{prop:chairQuestions}
	Given a rational $\lambda = p/q > 1$ and a rank $r$ between $1$ and $m - 2$, there exists a profile $P$ such that, for any weight vector $\w \in \W$, $a \in f(P)$ iff $w_{r} - w_{r+1} ≥ \lambda (w_{r+1} - w_{r+2})$ and $b \in f(P)$ iff $w_{r} - w_{r+1} ≤ \lambda (w_{r+1} - w_{r+2})$, where $f$ is the PSR parameterized with $\w$.
\end{proposition}

\begin{example*}
	Suppose we want to ask the following question to the chair: $w_{2} - w_{3} ≥ 2 (w_{3} - w_{4})$. In other words, we want to relate the difference between the weights of the second and third positions with the double of the difference between the weights of the third and fourth positions. We can rewrite this inequality in the form $w_{2} + 2 w_{4} ≥ 3 w_{3}$, and we can translate the original question in one of the form "is $a$ better than $b$?" where $a$ is an alternative ranked once in second position and twice in fourth position, and $b$ is ranked three times in third position. In order to do so, we construct a profile $P$ such that $a$ and $b$ respect these constraints and all the other alternative are strictly worse than them. 
	\begin{center}
		$
		\begin{array}{ccccc}
			\#\text{voters} \quad &w_1&w_2&w_3&w_4\\
			\mathbf{1} \quad &c&a&b&d\\
			\mathbf{2} \quad &d&c&b&a\\
			\mathbf{3} \quad &a&b&c&d\\
			\mathbf{3} \quad &b&a&d&c\\
		\end{array}.
		$
	\end{center}
	The score of the alternatives are $s(a)=3w_1+3w_2+w_2+2w_4$, $s(b)=3w_1+3w_2+3w_3$, $s(c)=w_1+2w_2+3w_3+3w_4$, $s(d)=2w_1+3w_3+4w_4$. Since the weights are convex $s(a)>s(c)$, $s(a)>s(d)$, $s(b)>s(c)$ and $s(b)>s(d)$. Therefore, if the committee picks $a$ in $P$, the answer to the original question is yes, the converse if $b$ is picked.
\end{example*}

At this stage, we are satisfied that a procedure exists to transform our abstract questions to questions about winners of a PSR. Further studies would investigate, for example, what is lost in terms of elicitation efficiency when we are forced to restrain to realistic concrete questions, meaning, questions involving small profiles; or investigate the relationship between our understanding of scores as (cardinal) utility and (ordinal) scores as definition of a PSR.

\paragraph{Elicitation strategies}
We develop several elicitation strategies for simultaneous elicitation of agent preferences and of the scoring rule.
While it is of course possible to first fully elicit the agent preferences and afterwards elicit weights, we want to investigate experimentally approaches that are able to recommend winning alternatives before obtaining complete knowledge of the profile or the rule.
%Indeed, it can be beneficial to split efforts asking questions to the chair and to agents, depending on which is estimated to be more informative.
We define here the various strategies we tested experimentally. A strategy tells us, given the current partial knowledge $(\pprofile, W)$, which question should be asked next.

The \strat{Random} strategy gives a baseline for comparison and informs about the difficulty of an elicitation problem. 
This strategy first chooses equiprobably whether it will ask a question about weights or a question about a preference ordering. If it opted for a question about weights, it draws one rank in $1 ≤ r ≤ m-2$ equiprobably, takes the middle of the interval of values for $\lambda$ that are still possible considering our knowledge so far, and asks whether $w_r - w_{r+1} ≥ \lambda (w_{r+1} - w_{r+2})$. The intervals are initialized to $[1, n]$: $\lambda≥1$ by convexity and we assume $\lambda≤n$ wlog, in fact for $\lambda≥n$, the rule coincides with Plurality. If it opted for a question to agents, it draws equiprobably among the agents whose preference is not known entirely; draws an alternative $a$ equiprobably among those involved in some incomparabilities in $\ppref_j$; and draws an alternative $b$ equiprobably among those incomparable with $a$ in $\ppref_j$.

Let $(x^{*},\bar{y}, \bar{\profile}, \bar{\w})$ be the current solution of the minimax regret, where $\bar{y}, \bar{\profile}, \bar{\w}$ are, respectively, the choice of $y$, the completion of the profile and the selection of weights for which $x^{*}$ is the minimax optimal alternative. 
The \strat{Pessimistic} strategy considers a set of $n + m$ candidate questions: one per agent, and one per rank.
The candidate questions to the agents use the heuristic proposed by \citet{Lu2011}: for each agent $j$, if $x^*$ and $\bar{y}$ are incomparable in $\ppref_j$, the candidate question concerns the pair $(x^*, \bar{y})$, otherwise, the candidate question concerns the pair $(x^*, z)$ for some $z$ incomparable to $x^*$ (randomly chosen), or if none such $z$ exist, the pair $(\bar{y}, z)$ for some $z$ incomparable to $\bar{y}$, or, if both $x^*$ and $\bar{y}$ are comparable to every alternatives in $\ppref_j$, any incomparable pair is picked at random. 
To understand the rationale behind the heuristic, 
recall that, as shown in the proof of \cref{claim:completion}, in order to increase $\PMR(x^{*},\bar{y})$, the adversary should place as many alternatives as possible above $x^{*}$ if $x^* \ppref_j \bar{y}$, and between $\bar{y}$ and $x^{*}$ if $\bar{y} \ppref_j x^*$.  
Responses to questions involving $x^*$ or $\bar{y}$ constrain the ability of the adversary to complete the profile in such manner, possibly reducing minimax regret.
The candidate questions to the chair are determined as in the Random strategy.

The Pessimistic strategy then selects among these $n + m$ candidate questions one that leads to minimal regret in the worst case, considering both possible answers to the question, and with penalty terms depending on the kind of question. To define this comparison precisely, assume that a question $q_1$ has type $t_1$ (being “chair” or “agent”), and leads to the new knowledge states $(\pprofile_1, W_1)$ if answered positively and $(\pprofile'_1, W'_1)$ if the answer is negative. 
Define $R^{\max}_1 = \max\set{\MMR(\pprofile_1, W_1), \MMR(\pprofile'_1, W'_1)}$
and $R^{\min}_1 = \min\set{\MMR(\pprofile_1, W_1), \MMR(\pprofile'_1, W'_1)} \epsilon_{t} + \epsilon'_{t}$.
%If $(\pprofile_1, W_1) ≥ (\pprofile'_1, W'_1)$, define $\MMR^{\max} = \MMR(\pprofile_1, W_1)$ and $\MMR^{\min} = \MMR(\pprofile'_1, W'_1)$; otherwise, define $\MMR^{\max} = \MMR(\pprofile'_1, W'_1)$ and $\MMR^{\min} = \MMR(\pprofile_1, W_1)$.
% and and $(\pprofile^\min_2, W^\min_2)$. numbering them so that $\MMR(\pprofile_1, W_1) ≥ \MMR(\pprofile_2, W_2)$. Then the badness of the question in the worst case is:
The terms $\epsilon_t$ and $\epsilon'_{t}$ are real numbers associated to the type $t$ of question; these parameters are to be determined experimentally and are used to fine control the choice of the question type.
Define similarly $t_2$, $R^{\max}_2$ and $R^{\min}_2$ for a question $q_2$.
We are now faced with the problem of aggregating these values in order to compare the informative values of the candidate questions. We adopt a pessimistic approach, reported to perform better than optimistic aggregation \citep{Cailloux2014}, although our experiments in this context suggested a weak impact of that choice on the performance of the strategy.
To avoid the absorption property of the max, we adopt $\leximax$ as an aggregator.
Pessimistic thus considers question $q_1$ to be better  than $q_2$ iff
\begin{align}
	R^{\max}_1 < R^{\max}_2 \text{ or } [R^{\max}_1 = R^{\max}_2 \text{ and } R^{\min}_1 < R^{\min}_2].
\end{align}
%This comparison gives a way of picking questions among a set of possible questions, by picking one that minimizes this approximate measure of minimax regret {\em a posteriori}. 
%The motivation for using this operator lies in 
In other words if the maximal {\em a posteriori} MMR of two questions are (nearly) equal, then it considers the (penalized) minimal MMR values, preferring the question with the lowest value.
(Technically, instead of applying a pure lexicographic aggregation, which is very sensitive to small errors due to floating-point computations, we apply a weighted sum between the maximal and the penalized minimal MMR values, with a predominant weight given to the maximal one, several order of magnitudes higher than the weight given to the penalized minimal MMR.)

The \strat{Extended pessimistic} strategy uses the same criterion as the pessimistic strategy, but extending it to a bigger set of candidate questions, the same as those considered by the Random strategy.
These candidate questions are then evaluated using the same operator as for the Pessimistic strategy, that is, we compute the minimax regret for the two possible answers, for each candidate question, and choose the best according to (quasi-)$\leximax$.
We use this strategy to test whether Pessimistic performs well: depending on the quality of the heuristic of the Pessimistic strategy, it might perform nearly equally well, or perhaps even better, than Extended pessimistic, while being (much) faster. Extended pessimistic is applicable only to small problem instances: its complexity is in $O(n^2 m^5)$, because we consider $O(m^2)$ questions for each agent and need for each question to compute MMR twice, whose complexity is $O(nm^3)$.

The \strat{Two phases} strategy is developed in order to investigate the effect of varying the proportion of questions asked to agents and to the chair, and compare the performance of asking questions to the chair first or to the agents first. It is parameterized by $q_c$, a value indicating the number of questions that must be asked to the chair.
The \strat{Two phases-ca} variant first asks $q_c$ questions to the chair, then $k - q_c$ questions to the agents, using in both cases Pessimistic to select the specific questions; whereas the \strat{Two phases-ac} variant starts with $k - q_c$ questions to the agents, then questions the chair. 
%Note that when asking first only questions to the chair, if the obtained knowledge approximates well the scoring vector, then in the second part of the elicitation we fall into the more classical setting of incompleteness of preferences assuming a known voting rule. 
%And vice-versa when asking first questions to the agents, the second part of the elicitation is similar to the setting of incompletely specified scoring rule. 
%This strategy also permits to simulate the current state of the art when considering incomplete preferences. By asking enough questions to the chair we can reduce our problem into a well studied one of incompleteness of preferences knowing the voting rule. Similarly, if we invert to whom ask questions first, we fall instead in an already studied case of uncertainty of the voting rule with a known complete profile. 

Finally, the \strat{Elitist} strategy aims at uncovering as quickly as possible the top alternative of each agent. It asks $m - 1$ questions to each agent in turn. 
Given an agent to query $j$, it asks about an alternative currently undominated in $\ppref_j$ and any alternative that it has not yet asked about for that agent, or equivalently, any alternative that is currently incomparable to this alternative. This approach guarantees that the top alternative in the ranking of $j$ will be known after having asked exactly $m-1$ questions to $j$.
After having asked $n (m-1)$ questions to the agents, it questions the chair only, using the same approach as the Pessimistic strategy.
This strategy can be expected to perform well when the chair assigns a large weight to the first rank, as compared to the other ranks. It will be useful to further challenge the Pessimistic strategy, which is not specifically tailored to such a situation.

%\item {\em Volumetric} strategy: chooses an agent $i$ and a query that maximizes the number of new pairwise preferences revealed given the worst response.

\section{Empirical Evaluation} 
\label{sec:experiments}
We  performed a number of numerical experiments in order to validate our approach and to test the performance of the different elicitation strategies. %Our experiments are described by topic here below. 
We start by describing the general protocol of experimentation. %use the following protocol, deviations are indicated below for each experiment.
Having picked a problem size $(m, n)$, a number of questions $k$ and a strategy to test, we randomly generate an “oracle”, representing the true preferences of the agents (i.e. the linear orders) and the weights associated with the chair's scoring rule. 
The preferences are generated following an impartial culture assumption: the linear order of each agent is generated independently from the other ones and all have the same probability of appearing. IC is a quite challenging situation: as can be expected intuitively (and shown experimentally by \citet{Lu2011} in their setting), the number of questions to be asked decrease with less varied profiles. We want to focus on the most critical setting, as there is a wide variety of possible situations to test in such experiments.
For generating the weights we first draw $m - 1$ numbers uniformly at random (in the interval $\intvl{0,1}$ representing weight ``differences''), normalize and sort them; 
a sequence of convex decreasing weight is then obtained by a decumulative sum.
The penalty parameters for the Pessimistic and Extended pessimistic strategies are set to $\epsilon_{\text{chair}} = 1.1$, $\epsilon'_{\text{chair}} = 10^{-6}$, $\epsilon_{\text{agent}} = 1.0$ and $\epsilon'_{\text{agent}} = 0$.

We start with empty knowledge ($\pprofile = (\emptyset, \emptyset, …), W = \W$) about the preference orderings of the agents or the weight differences favored by the chair. We obtain the first question to be asked using the strategy under test, as described above. We then use the oracle to answer the question and update the system's knowledge, which is thus used to obtain the next question. This is repeated until $k$ answers have been obtained, computing the resulting MMR values along the way for various values of $k$. We repeat this whole experiment a variable number of times indicated below, for a given $(m, n, k)$, and report the average resulting MMR and the standard deviation \textit{sd}. The sizes of the considered scenarios are comparable to the ones used by \citet{Cailloux2014}. 

\begin{figure}[t]
	\caption{Average MMR in problems of size $(5, 10)$ after $k$ questions.}
	\label{fig:smallSize}
	\begin{tikzpicture}
		\begin{axis}[
			y=10,
			xlabel=Number of Questions,
			ylabel=Avg. Regret,
			ytick={0,2,4,6,8,10,12},
			xtick distance=10,
			ytick distance=2,
			xtick pos=left,
			ymajorgrids=true,
			ytick style={draw=none},
			ymin=0,
			ymax=12,
			xmin=0,
			xmax=100,
			yticklabels={0,2,4,6,8,10,12}]
			\addlegendimage{mark=*,teal,mark size=2}
			\addlegendimage{mark=triangle*,orange,mark size=2}
			\addlegendimage{mark=square*,blue,mark size=2}
			\addlegendimage{mark=diamond*,red,mark size=2}
			
			\addplot[thick, mark=*, mark size = {2}, mark indices = {35}, teal] table [x=k, y=Pes.]{data/comparison.dat};
			\addlegendentry{Pes.}
			\addplot[thick, mark=triangle*, mark size = {2}, mark indices = {45}, orange] table [x=k, y=Ex.Pes.]{data/comparison.dat};
			\addlegendentry{Ex.Pes.}
			\addplot[thick, mark=square*, mark size = {2}, mark indices = {50}, blue] table [x=k, y=Eli.]{data/comparison.dat};
			\addlegendentry{Eli.}
			\addplot[thick, mark=diamond*, mark size = {2}, mark indices = {50}, red] table [x=k, y=Rnd.]{data/comparison.dat};
			\addlegendentry{Rnd.}
		
		\end{axis}
	\end{tikzpicture}
\end{figure}

%\begin{figure}
%	\caption{Average MMR in problems of size $(5, 10)$ after $k$ questions.}
%	\label{fig:smallSize}
%%	\Description{Graph showing that Pessimistic performs slightly better than Extended pessimistic, itself performing better than Elitist, itself performing much better than Random.}
%	\includegraphics[width=.45\textwidth]{comparison.png}
%\end{figure}
\sisetup{table-number-alignment = center, table-figures-integer=2, table-figures-decimal=1, table-auto-round}
\begin{table}
	\caption{Average MMR in problems of size $(10, 20)$ after $k$ questions.}
	\label{tab:biggerSize}
	\begin{tabular}{S[table-figures-integer=3, table-figures-decimal=0]S[table-number-alignment = right]@{ ± }S[table-number-alignment = left, table-figures-integer=1]S[table-number-alignment = right]@{ ± }S[table-number-alignment = left, table-figures-integer=1]S[table-number-alignment = right]@{ ± }S[table-number-alignment = left, table-figures-integer=1]S[table-number-alignment = right]@{ ± }S[table-number-alignment = left]}
		\toprule
		{k} & {Rnd.} & {sd} & {Pes.} & {sd} & {Eli.} & {sd} \\
		\midrule
		0 &20.0 & 0.0 & 20.0 & 0.0&  20.0 & 0.0 \\
		50 & 19.82 & 0.04 &	15.59 &0.56	&17.38& 0.7\\
		100 & 19.12	& 0.26&	11.91&	1.26 &15.23& 0.73\\
		150 & 18.06	& 0.47&	8.92&	1.53 &13.38& 1.11\\
		200 & 16.89	& 0.62&6.24&2.02&11.76& 1.03\\
		250 & 15.63 & 0.84&	4.64&1.72&10.56& 0.89\\
		300 & 14.72	& 0.94&	3.01& 1.35 &10.48& 0.87\\
		350 & 13.41	& 1.15& 1.76& 0.95&10.48& 0.86\\
		400 & 11.98	& 0.68&	0.62&0.56 &10.48& 0.86\\
		\bottomrule
	\end{tabular}
\end{table}
\begin{table}[t]
	\caption{Average MMR in problems of size $(10, 20)$ and geometric weights after $k$ questions.}
	\label{tab:geometricWeights}
	\begin{tabular}{S[table-figures-integer=3, table-figures-decimal=0]S[table-number-alignment = right]@{ ± }S[table-number-alignment = left, table-figures-integer=1]S[table-number-alignment = right]@{ ± }S[table-number-alignment = left, table-figures-integer=1]}
		\toprule
		{k} & {Pes.} & {sd} & {Eli.} & {sd} \\
		\midrule
		0	&20.0	&0.0	&20.0	&0.0\\
		50	&15.96	&0.54	&17.26	&0.42\\
		100	&12.48	&0.93	&15.6	&0.43\\
		150	&9.58	&1.37	&13.94	&0.76\\
		200	&7.43	&1.25	&10.95	&1.12\\
		250	&5.26	&1.52	&6.6	&0.79\\
		300	&3.47	&1.32	&6.57	&0.79\\
		\bottomrule
	\end{tabular}
\end{table}
\paragraph{Comparison of strategies}
Our first experiment concerns small size situations.
\Cref{fig:smallSize} compares some of our strategies in the case $m = 5, n = 10$ (variations around this size yield similar conclusions), where the results are averaged over $200$ runs.
%(The figure also displays the performance of the Elitist strategy, to which we will come back.)
We see that asking random questions does not allow to reach a low regret level even after having asked 100 questions, whereas a low regret level ($\MMR$ = 1) is reached by Pessimistic before having asked 60 questions.
We also see that Pessimistic performs slightly better than Extended pessimistic, showing that Pessimistic chooses candidate questions wisely; this is good news since Pessimistic is much faster: it takes on average only $16$s for a complete elicitation session (for $m = 5$, $n = 10$ and $100$ questions), while Extended pessimistic takes $50$s. Notice that although they exhibit a close performance, Pessimistic performs consistently better, in the sense that the numbers are systematically in favor of Extended pessimistic when performing the experiment again.
\Cref{tab:biggerSize} shows that these conclusions also hold for a problem of larger size ($m = 10, n = 20$), except that this table does not feature Extended pessimistic, which is too slow to be run repeatedly on such instance.

We also compared the Pessimistic strategy against Elitist in a situation specifically tailored to advantage Elitist. For that experiment specifically, instead of drawing the weights of the oracle randomly, we fix it to a “geometric” weight vector, such that $w_r - w_{r + 1} = 2(w_{r + 1} - w_{r + 2})$, for all $r ≤ m - 2$, so as to dramatically increase the importance of the weights associated to the top ranks. Even in that case, we see in \cref{tab:geometricWeights} that Pessimistic performs better than Elitist.

%\subsection{Absolute evaluation of Pessimistic strategy}
\begin{table}
	\caption{Number of questions needed by Pessimistic strategy to reach an MMR of $\frac{n}{10}$ (represented by $k_{\MMR}$), by size.}
	\label{tab:lowRegret}
	\begin{tabular}{S[table-figures-decimal=0]S[table-figures-decimal=0]SS[table-figures-integer=3, table-figures-decimal=0]}
		\toprule
		{m} & {n} & {$\frac{n}{10}$} & {$k_{\MMR}$} \\
		\midrule
		5 & 10 & 1 & 60 \\
		5 & 15 & 1.5 & 80 \\
		5 & 20 & 2 & 110 \\
		10 & 20 & 2 & 340 \\
		10 & 30 & 3 & 527 \\
		15 & 30 & 3 & 951 \\
		\bottomrule
	\end{tabular}
\end{table}

\paragraph{In-depth evaluation of Pessimistic}
\label{sec:lowRegret}
While in previous experiments we compared Pessimistic to the other strategies, in this set of experiments, we evaluate the Pessimistic strategy in absolute terms. 
We first wonder how many questions should be asked in order to reach a low regret level. Here, we consider a low level to be a tenth of the number of agents ($n/10$): such a regret is equivalent to the difference of score of an alternative $x$ that results from switching from a profile $P$ to a profile $P'$ where ten percent of the agents rank $x$ last instead of first.
The results for various sizes are displayed in \cref{tab:lowRegret}. 
For the experiments we performed, we see that the number of questions required to reach a low regret level grows approximately linearly with the number of agents and grows less fast than the square of the number of alternatives. Averaging these data by category of value for $m$, and assuming no questions get asked to the chair, we see that in order to reach a low regret level, each agent will have to answer $5.6$ questions for $m = 5$, $17.2$ questions for $m = 10$ and $27.1$ questions for $m = 15$. These numbers have to be contrasted with the estimated number of questions required to elicit the full preference of an agent which are $6.6$ for $m=5$, $24.8$ for $m=10$ and $48.4$ for $m=15$. To obtain these data, we constrained the Pessimistic strategy to ask questions to the agents only, and ran it on a single agent problem, with various values for $m$.

%\begin{table}
%	\caption{Number of questions needed by the Pessimistic strategy to elicit the complete preference of one agent.}
%	\label{tab:fullProfile}
%	\begin{tabular}{S[table-figures-decimal=0]S}
%		\toprule
%		{m} & {k} \\
%		\midrule
%		5 & 6.6\\
%		10 & 24.8\\
%		15 & 48.4\\
%		\bottomrule
%	\end{tabular}
%\end{table}

%\subsection{Decrease in MMR values}


\begin{figure}[t]
	\caption{Average MMR (normalized on the number of voters $n$) after $k$ questions with Pessimistic strategy for different problem sizes.}
	\label{fig:linearity}
	\begin{tikzpicture}
		\pgfplotsset{
			every axis legend/.append style={
				at={(0.5,1.1)},
				anchor=south
			},
		}
		\begin{axis}[
			y=100,
			legend columns=3,
			xlabel=Number of Questions,
			ylabel=MMR/n,
			ytick={0,0.5,1},
			xtick distance=100,
			xtick pos=left,
			ymajorgrids=true,
			ytick style={draw=none},
			ymin=0,
			ymax=1,
			xmin=0,
			xmax=1000,
			yticklabels={0,0.5,1}]
			
			\addlegendimage{mark=triangle*,teal,mark size=2}
%			\addlegendimage{mark=*,violet,mark size=2}
			\addlegendimage{mark=square*,green,mark size=2}
			\addlegendimage{mark=diamond*,red,mark size=2}
			\addlegendimage{mark=pentagon*,cyan,mark size=2}
			\addlegendimage{mark=halfcircle*,violet,mark size=2}
			\addlegendimage{mark=*,pink,mark size=2}
			\addlegendimage{mark=halfsquare left*,blue,mark size=2}
			\addlegendimage{mark=halfsquare right*,brown,mark size=2}
			\addlegendimage{mark=halfsquare*,magenta,mark size=2}
			
			
			\addplot[thick, mark=triangle*, mark size = {2}, mark indices = {35}, teal] table [x=k, y=5.10]{data/normalizedLin.dat};
			\addlegendentry{m=5, n=10}
%			\addplot[thick, mark=*, mark size = {2}, mark indices = {45}, violet] table [x=k, y=5.15]{data/normalizedLin.dat};
%			\addlegendentry{m=5, n=15}
			\addplot[thick, mark=square*, mark size = {2}, mark indices = {90}, green] table [x=k, y=5.20]{data/normalizedLin.dat};
			\addlegendentry{m=5, n=20}
			\addplot[thick, mark=diamond*, mark size = {2}, mark indices = {150}, red] table [x=k, y=10.20]{data/normalizedLin.dat};
			\addlegendentry{m=10, n=20}
			\addplot[thick, mark=pentagon*, mark size = {2}, mark indices = {300}, cyan] table [x=k, y=10.30]{data/normalizedLin.dat};
			\addlegendentry{m=10, n=30}
			\addplot[thick, mark=halfcircle*, mark size = {2}, mark indices = {400}, violet] table [x=k, y=tshirt]{data/normalizedLin.dat};
			\addlegendentry{tshirts m11n30}
			\addplot[thick, mark=*, mark size = {2}, mark indices = {400}, pink] table [x=k, y=courses]{data/normalizedLin.dat};
			\addlegendentry{courses m9n146}
			\addplot[thick, mark=halfsquare left*, mark size = {2}, mark indices = {200}, blue] table [x=k, y=14.9]{data/normalizedLin.dat};
			\addlegendentry{m=14, n=9}
			\addplot[thick, mark=halfsquare right*, mark size = {2}, mark indices = {60}, brown] table [x=k, y=skate]{data/normalizedLin.dat};
			\addlegendentry{skate m14n9}
			\addplot[thick, mark=halfsquare*, mark size = {2}, mark indices = {400}, magenta] table [x=k, y=15.30]{data/normalizedLin.dat};
			\addlegendentry{m=15, n=30}
		\end{axis}
	\end{tikzpicture}
\end{figure}

%\begin{figure}
%	\caption{Average MMR after $k$ questions with Pessimistic strategy for different problem sizes.}
%	\label{fig:linearity}
%	\begin{tikzpicture}
%		\pgfplotsset{
%			every axis legend/.append style={
%				at={(0.5,1.03)},
%				anchor=south
%			},
%		}
%		\begin{axis}[
%			y=3.5,
%			legend columns=3,
%			xlabel=Number of Questions,
%			ylabel=Avg. Regret,
%			ytick={0,5,10,15,20,25,30},
%			xtick distance=100,
%			ytick distance=5,
%			xtick pos=left,
%			ymajorgrids=true,
%			ytick style={draw=none},
%			ymin=0,
%			ymax=31,
%			xmin=0,
%			xmax=1000,
%			yticklabels={0,5,10,15,20,25,30}]
%			
%			\addlegendimage{mark=triangle*,teal,mark size=2}
%			\addlegendimage{mark=*,violet,mark size=2}
%			\addlegendimage{mark=square*,green,mark size=2}
%			\addlegendimage{mark=diamond*,red,mark size=2}
%			\addlegendimage{mark=halfsquare left*,blue,mark size=2}
%			\addlegendimage{mark=halfsquare right*,brown,mark size=2}
%			\addlegendimage{mark=pentagon*,cyan,mark size=2}
%			\addlegendimage{mark=halfsquare*,magenta,mark size=2}
%			
%			
%			\addplot[thick, mark=triangle*, mark size = {2}, mark indices = {35}, teal] table [x=k, y=5.10]{data/linearity.dat};
%			\addlegendentry{m=5, n=10}
%			\addplot[thick, mark=*, mark size = {2}, mark indices = {45}, violet] table [x=k, y=5.15]{data/linearity.dat};
%			\addlegendentry{m=5, n=15}
%			\addplot[thick, mark=square*, mark size = {2}, mark indices = {90}, green] table [x=k, y=5.20]{data/linearity.dat};
%			\addlegendentry{m=5, n=20}
%			\addplot[thick, mark=diamond*, mark size = {2}, mark indices = {150}, red] table [x=k, y=10.20]{data/linearity.dat};
%			\addlegendentry{m=10, n=20}
%			\addplot[thick, mark=halfquare left*, mark size = {2}, mark indices = {60}, blue] table [x=k, y=14.9]{data/linearity.dat};
%			\addlegendentry{m=14, n=9}
%			\addplot[thick, mark=halfsquare right*, mark size = {2}, mark indices = {60}, brown] table [x=k, y=skate]{data/linearity.dat};
%			\addlegendentry{skate m14n9}
%			\addplot[thick, mark=pentagon*, mark size = {2}, mark indices = {300}, cyan] table [x=k, y=10.30]{data/linearity.dat};
%			\addlegendentry{m=10, n=30}
%			\addplot[thick, mark=halfsquare*, mark size = {2}, mark indices = {400}, magenta] table [x=k, y=15.30]{data/linearity.dat};
%			\addlegendentry{m=15, n=30}
%			
%		\end{axis}
%	\end{tikzpicture}
%\end{figure}


%\begin{figure}
%	\caption{Average MMR after $k$ questions with Pessimistic strategy for different problem sizes.}
%
%	%\Description{Graph showing that the MMR decreases very approximately linearly, and is convex, as a function of the number of questions.}
%	\includegraphics[width=.45\textwidth]{linearity.png}
%\end{figure}

\paragraph{Decrease in MMR values}
We next wonder how fast the regret decreases, measured as a function of the number of questions asked. This is important practically because it may be impossible or undesirable to ask sufficient questions to reach a low regret level. Knowing the speed of decrease permits to know which trade-offs can be achieved between the quality of the resulting recommendation and the number of questions that participants have to answer. \Cref{fig:linearity} shows graphically the decrease in MMR according to the number of questions asked for various problem sizes. We see that this function is convex, apart from the very first few questions, indicating %to users of our approach 
that, on average, halving the number of questions will only reduce the gain in regret by less than half. \commentBN{Reviewer: Halving the number of questions reduces the regret by more than 50\%.}

At the start of the elicitation, the space of uncertainty is so large that the adversary can attain the maximum possible value of regret; multiple answers are needed to constrain her enough for the MMR to start decreasing. When approaching optimality, the pace of MMR reduction decreases.

% do less harm than halving the gain in regret, on average.

%\subsection{Value of information comparison}
\paragraph{Comparison with Two Phase}
\begin{table}
	\caption{Average MMR in problems of size $(10, 20)$ after $400$ questions, among which $q_c$ to the chair.}
	\label{tab:twoP400}
	\begin{tabular}{S[table-figures-integer=3, table-figures-decimal=0]S[table-number-alignment = right]@{ ± }S[table-number-alignment = left, table-figures-integer=1]S[table-number-alignment = right]@{ ± }S[table-number-alignment = left, table-figures-integer=1]}
		\toprule
		{$q_c$} & {2 ph.\ ca} & {sd} & {2 ph.\ ac} & {sd} \\
		\midrule
		0 & 0.66 & 0.67 & 0.65 & 0.65  \\
		15 & 0.71 & 0.73 & 0.67	& 0.64 \\
		30 & 0.62 & 0.5 & 0.8 & 0.62 \\
		50 & 1.23 & 1.46 & 0.8 & 0.79 \\
		100 & 2.03 & 1.56 & 1.88 & 1.02  \\
		150 & 3.41 & 1.79 & 4.07 & 1.51 \\
		200 & 4.61	& 1.35  & 6.53 & 2.0  \\
		250 & 8.4 & 1.86 & 	7.69 & 1.24 \\
		300 &11.07 & 0.86& 11.87 & 1.25 \\
		350 &15.06 & 0.68&15.59 & 0.6 \\
		400 &20.0 & 0.0 & 20.0 & 0.0 \\
		\bottomrule
	\end{tabular}
\end{table}

The experiments so far let the strategy target its questions unrestrictively, leaving open the possibility of questioning either the chair or an agent at each step. One may wonder what is lost in terms of regret by asking different proportions of questions to the chair and the agents. Such restrictions may be useful because of (partial) unavailability of the chair, or because the estimated cognitive costs may differ sensibly, as these types of questions differ in nature. 
\Cref{tab:twoP400} shows the MMR value reached in problems of size $m = 10, n = 20$ after $400$ questions, using the Two phases strategy, in the “ca” (chair then agents) and in the “ac” (agents then chair) variants. These numbers are to be compared with the MMR value reached after 400 questions with the Pessimistic strategy (displayed in \cref{fig:linearity}), which is $0.6$.
The Pessimistic strategy asks on average $48$ questions to the chair in this setting.

These numbers highlight that it is possible to obtain a good-quality recommendation while knowing only that the voting rule is a scoring rule and that the weights are convex, which is our basic hypothesis (corresponding to the line $q_c = 0$, where no question is asked to the chair).

\section{Conclusions}  
\label{sec:conclusions}
In this paper we have considered a social choice setting with partial information about the agent's preferences and a partially specified voting rule.
In this setting, we have proposed the use of minimax regret both as a means of robust winner determination as well as a guide to the process of simultaneous elicitation of preferences and voting rule.
Our experimental results %on randomly generated and real world data sets 
suggest that regret-based elicitation is effective and allows to quickly reduce worst-case regret significantly. They also show that, in our setting, good quality (low regret) recommendations can be achieved short of knowing the weights precisely or the profile completely.
%regret, but they also show that starting with zero knowledge became a pretentious approach really quickly when increasing the size of the problem. Future works will therefore include the test of these strategies on partial specified profiles, ideally on real datasets. An other important direction is the extension to voting rules beyond scoring rules.
%Regret-based elicitation allows to determine near-optimal winners using only few information about the agent preferences.

An open-source library, allowing to reproduce our experiments, will be made publicly available.\footnote{URL not displayed for anonymity reasons.}
%and serve as a basis for further research

We mention some directions for future works.
Further development of elicitation strategies, considering alternative heuristics, is an important direction. 
Second, elicitation could be extended to voting rules beyond scoring rules. 
Finally, an important direction of extension aims at studying how to elicit preferences while restraining to concrete and easy questions.
% Acknowledgments: We thank the reviewers for comments helping to improve the paper. 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%% The acknowledgments section is defined using the "acks" environment
%%% (rather than an unnumbered section). The use of this environment 
%%% ensures the proper identification of the section in the article 
%%% metadata as well as the consistent spelling of the heading.

%\begin{acks}
%If you wish to include any acknowledgments in your paper (e.g., to 
%people or funding agencies), please do so using the `\texttt{acks}' 
%environment. Note that the text of your acknowledgments will be omitted
%if you compile your document with the `\texttt{anonymous}' option.
%\end{acks}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%% The next two lines define, first, the bibliography style to be 
%%% applied, and, second, the bibliography file to be used.
%\bibliographystyle{abbrvnat} 
%\bibliography{biblio}

\newpage

\bibliographystyle{named}
\bibliography{biblio}

\newpage
\appendix
\section{Appendix}
\begin{sketch*}[\cref{claim:completion}]
	Consider our knowledge $\pprefeq_j$ about the preference of the agent $j$. 
	The adversary's goal is to make the score of $y$ as high as possible and the score of $x$ as low as possible. 
	To do this, he should complete $\ppref_j$ to $\pref_j$ by putting above $x$ as many alternatives as he can, that is, all the alternatives except those that are known to be worse than $x$ (those $a$ such that $x \pprefeq_j a$); and similarly, he should put below $y$ all the alternatives he can. Two conditions must be excluded for $a$ to go below $y$. The alternatives such that $a \pprefeq_j y$ can’t be put below $y$.
	Furthermore, the first objective must take priority over the second one: when an alternative should go above $x$ according to the first objective (because $¬(x \pprefeq_j a)$), and $x$ is known to be better than $y$ (thus $x \pprefeq_j y$), then $a$ should be put above $x$ (irrespective of whether $a \pprefeq_j y$), which will move both $x$ and $y$ one rank lower than if $a$ had been put below $y$. 
	This maximizes the adversary’s interests: because the weight vector is convex, the difference of scores will be lower when both alternatives are ranked lower (Equation \ref{eq:convexity}), and that difference of scores is in favor of $x$ when $x \ppref_j y$, thus to be minimized from the point of view of the adversary.
\end{sketch*}

\begin{proof*}[\cref{claim:rankPMR}]
	The rank of $x$ is directly obtained from \cref{eq:complx}. The rank of $y$ is obtained by complementing \cref{eq:comply}, obtaining $a \prefeq_j y ⇔ (a \pprefeq_j y) ∨ ((x \pprefeq_j y) ∧ ¬(x \pprefeq_j a))$, and, observing that $a \pref_j y ⇔ a ≠ y ∧ a \prefeq_j y$, obtaining that $a \pref_j y$ if and only if
	\begin{equation}
		\label{eq:betteryinter}
		(a \neq y) ∧ [(a \pprefeq_j y) ∨ ((x \pprefeq_j y) ∧ ¬(x \pprefeq_j a))],
	\end{equation} 
	or equivalently, if and only if
	\begin{equation}
		\label{eq:bettery}
		%a \pref_j y ⇔ 
		(a \ppref_j y) ∨ ((x \pprefeq_j y) ∧ ¬(x \pprefeq_j a)).
	\end{equation} 
	Indeed, \eqref{eq:betteryinter} $⇒$ \eqref{eq:bettery}, and \eqref{eq:bettery} $⇒$ \eqref{eq:betteryinter} because $(x \pprefeq_j y) ∧ ¬(x \pprefeq_j a) ⇒ a ≠ y$ (as when $a = y$, $(x \pprefeq_j y)$ and $¬(x \pprefeq_j a)$ are opposite claims). Suffices now to rewrite \cref{eq:bettery} to let the two disjuncts designate disjoint sets:
	\begin{equation}
		\label{eq:betteryfinal}
		a \pref_j y ⇔ 
		(a \ppref_j y) ∨ ((x \pprefeq_j y) ∧ ¬(x \pprefeq_j a) ∧ ¬(a \ppref_j y)).
	\end{equation}
\end{proof*}

\begin{proof*}[\cref{prop:chairQuestions}]
	Define a linear order $>_1$ over $A$ as placing $a$ at rank $r$, $b$ at rank $r + 1$, and the remaining alternatives arbitrarily. 
	Define a linear order $>_2$ over $A$ as placing $a$ at rank $r + 2$, $b$ at rank $r + 1$, and the remaining alternatives arbitrarily.
	Define an arbitrary linear ordering $>$ over $A \setminus \set{a, b}$. 
	Define a linear order $>_3$ as placing $a$ first, $b$ second, and following the order of $>$ for the remaining positions.
	Finally, define a linear order $>_4$ as placing $b$ first, $a$ second, and following the \emph{inverse} order of $>$ for the remaining positions.
	
	Define $P$ as the profile of $3 (p + q)$ voters containing $q$ times $>_1$, $p$ times $>_2$, and $>_3$ and $>_4$ each $p + q$ times.
	As a result, $a$ obtains the following ranks: $q$ times $r$, $p$ times $r + 2$, $p + q$ times first, and $p + q$ times second. The alternative $b$ obtains the ranks $r + 1$, $2$ and $1$, each $p + q$ times. Consider any alternative $c \in A \setminus \set{a, b}$. Its score is maximal when it comes first in $>_1$, first in $>_2$ and first in $>$, by convexity of the weights. In that case, $c$ is positioned at the ranks $1$, $3$ and $m$, each $p + q$ times. 
	
	Letting $s(x)$ denote the score of $x$ at $P$, we obtain $s(a) = q w_r + p w_{r + 2} + (p + q) w_1 + (p + q) w_2$, thus, $s(a) ≥ (p + q) w_m + (p + q) w_1 + (p + q) w_2$; $s(b) = (p + q) w_{r + 1} + (p + q) w_2 + (p + q) w_1$; and, $\forall c \in A \setminus \set{a, b}$, 
	$s(c) ≤ (p + q) w_1 + (p + q) w_3 + (p + q) w_m$. It follows that $a$ or $b$ maximize $s$ (as $s(a) ≥ s(c)$). We conclude by observing that $a \in f(P) ⇔ s(a) ≥ s(b) ⇔ q w_r + p w_{r + 2} ≥ (p + q) w_{r + 1} ⇔ w_r - w_{r + 1} ≥ (p / q) (w_{r + 1} - w_{r + 2})$, and similarly for $b \in f(P)$.
\end{proof*}

\end{document}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%




%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%



