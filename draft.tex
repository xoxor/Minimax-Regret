\documentclass[12pt]{article}
\usepackage[top=2cm, bottom=2cm, left=2cm, right=2cm]{geometry}
\geometry{a4paper}
%\usepackage{authblk}

\usepackage{graphicx}
\usepackage{amsmath,amssymb,enumerate,amsthm}
\usepackage{hyperref}
\usepackage{mathrsfs}
\usepackage{algorithm, algpseudocode}
\usepackage{bm}
\usepackage{cleveref}
\usepackage{xcolor}
\usepackage{booktabs}

\newcommand{\email}[1]{\href{mailto:#1}{#1}}
\newcommand{\denselist}{\itemsep -2pt\topsep-6pt\partopsep-6pt}
\newcommand{\commentOC}[1]{\textcolor{blue}{\small$\big[$OC: #1$\big]$}}

%\newcommand{\rank}{\text{rank}}
\newcommand{\rank}{v}
\newcommand{\preflarge}{\boldsymbol{\succeq}^\textbf{r}}%real, complete pref
%\newcommand{\pref}{\boldsymbol{\succ}^\textbf{r}}%real, connected pref, strict
\newcommand{\pref}{\succ}%real, connected pref, strict
\newcommand{\prefr}{{\succ}^\text{r}}%real, connected pref, strict
\newcommand{\ppreflarge}{\succeq^\text{p}}%partial pref
\newcommand{\ppref}{\succ^\text{p}}%partial pref
%Thanks to https://tex.stackexchange.com/q/154549
\makeatletter
\newcommand{\newrelation}[2]{% #1 = control sequence, #2 = replacement text
  \@ifdefinable{#1}{%
    \def#1{%
    \@ifnextchar_{\csname\string#1\endcsname}{\mathrel{#2}}%
    }%
    \@namedef{\string#1}##1##2{\mathrel{#2_{##2}}}%
  }%
}
\makeatother

\newrelation{\myRgood}{R^X}
\newrelation{\pinc}{Q^\text{p}}%partial pref, complement (incomparable)

\newcommand{\profile}{\textbf{v}}%(complete) profile
\newcommand{\pprofile}{\textbf{p}}%partial profile
\newcommand{\w}{\textbf{w}}%partial profile

\DeclareMathOperator{\Regret}{Regret}
\DeclareMathOperator{\SCORE}{Score}
\DeclareMathOperator{\PMR}{PMR}
\DeclareMathOperator{\MR}{MR}
\DeclareMathOperator{\MMR}{MMR}

\algrenewcommand\algorithmicrequire{\textbf{Input:}}
\algrenewcommand\algorithmicensure{\textbf{Output:}}
\newtheorem{claim}{Claim}
\newtheorem{corollary}{Corollary}
\newtheorem{definition}{Definition}

\title{Robust Winner Determination and Simultaneous Elicitation of Scoring Rules and Preferences}
%\author{}
\author{Olivier Cailloux  \and Beatrice Napolitano \and Paolo Viappiani} %\affil{LIP6\\\email{paolo.viappiani@lip6.fr}
%\author{Olivier Cailloux} 
%\author{Stefano Moretti}%\affil{LAMSADE}
%\author{Beatrice Napolitano}\affil{LAMSADE}

\begin{document}
\maketitle
% aggregate different opinions

%Given a full profile: use linear programming to maximize regret
%Given a partial profile: use techniques of Lu and Boutilier (2011).
\begin{abstract}
Social choice deals with the problem of determining a consensus choice from the preferences of different agents (voters).
In the classical setting, the voting rule is fixed beforehand and full preference information is provided by the voters. 
Recently, the assumption of full preference information has been questioned by a number of researchers and 
number of frameworks for vote elicitation have been proposed.

In this paper we go one step further and we assume that both the voting rule and the voters preferences are partially specified.
Focusing on positional scoring rules, we assume that the chair %is not able to give the definition of the rule but 
is able to answer simple questions  requiring to pick a winner from a specific  example profile.
Moreover, the preferences of the voters are incrementally acquired by asking comparison queries.

We propose a method  for robust approximate winner determination in this setting with minimax regret. 
We then provide an interactive elicitation protocol based on minimax regret
%We then show how minimax regret can be used to drive the elicitation in order to ask informative queries in order to a
and develop several query strategies that interleave questions to the chair and questions to the voters in order to acquire the most relevant information about the preferences and voting rule.
\end{abstract}

\section{Introduction}
% indeed many works analyze the properties of different rules (including axiomatic treatments) in order to justify the choice of specific social choice functions. 
%Moreover, it is usually assumed that the preferences of the voters are known completely. 


%General motivation: need to deal with partially specified preferences and as well partially specified voting rules
Aggregation of preference information is a central task in many computer systems (recommender systems, search engines, etc).
In many situations, such as in group recommender systems, the goal is to find a consensus choice.

The traditional approach to social choice assumes that both the social function and the full preference orderings of the voters are expressed beforehand. 
As noted by several authors requiring voters to express full preference orderings can be onerous (especially for 
large sets of alternatives).
Acquiring the necessary preference information may require a high cognitive and communication cost.

%Recently, the assumption of full a has been questioned by a number of researchers
In many real situations, however, it may be necessary to reason with partial preferences, as some preferences are not available and too expensive to obtain (with respect to a cognitive or economic cost). 
This observation has motivated a number of recent works on preference elicitation, including several works on social choice with partial profiles.

We argue that it is possible that the committee wants to precise some preferences about the aggregation.s

In this paper we depart from the classic view by considering that both preferences and the social choice rule can be only partially specified.

We develop methods for computing the minimax-optimal alternative for scoring rules with partial preference information and partial information about the weights.

%
% Incremental elicitation of preferences is critical to easing the cognitive and communication cost for users 
%In this paper we provide a method for approximate winner determination and an incremental elicitation protocol based on minimax regret. 
%In this paper we relax the traditional assumptions.



%Incremental elicitation of preferences can help mitigating the cognitive and communication costs
%We adopt an adaptive utility elicitation framrwork

%Focus on positional scoring rules
We focus on positional scoring rules, that  are a particularly common methods used to aggregate rankings and determine  a winner.
We also address the problem of elicitation, providing incremental elicitation methods to acquire relevant preference information.%The score can be seen as a utility for the society.
%and often captures more information than is needed to determine the winner
We discuss  heuristics that allow us to determine queries that quickly allow to reduce minimax regret.


Possible and necessary winner determination: in typical settings, there will be no necessary winner and too many possible winners.


While previous works have considered either partial preferences or a partially specified aggregation, but we do not know of any work considering both sources of uncertainty at the same time.

%We consider that the committee wants to express preferences for some voting rules

We develop several query strategies that  focus simultaneously on reduction of relevant preference and voting rule uncertainty.
% We must engage in simultaneous elictation of the rule and of the preferences.

%In this paper we propose an interactive adaptive protocol for eliciting both the voters preferences and the voting rule.
%At each step we need to decide whether we want to ask a question to the committee or to one of the agents (and to which agent in particular).

%We want to design a questioning strategy to minimize the worst regret in the long run. A questioning strategy indicates, given a partial profile and a set of feasible weights, which question to ask next. A question is either a query to the voter $i$ about her preference relation $\succ_i$ or a query to the committee about the feasible weights. 

%The voting scheme selects the winner (a consensus option).
%Incremental elicitation 
The paper is organized as follows.
In Section \ref{sec:background} we provide the necessary background.
We introduce the minimax criterion and in Section \ref{sec:mmr}.
In Section \ref{sec:elicit} we provide an interactive elicitation protocol based on minima regret; finally in Section 
\ref{sec:conclusions} we provide some final thoughts.

\begin{itemize}
\item References: \cite{Cailloux2014}, \cite{Llamazares2013}, \cite{Konczak05}, \cite{Kalech2011}, \cite{Pini2009}, relation to necessary and possible winners \cite{Xia2008}.
Also this reference: \cite{Naamani-Dery2015}.
\end{itemize}

%\subsection{Related works}
\paragraph{Uncertain scoring rules}
A number of works have dealt with the problem of reasoning with incompletely specified aggregation functions.
In particular, when considering positional scoring rules, it is possible to derive dominance relations (akin to stochastic dominance) that allow to eliminate some alternatives since they will be less preferred than another one for any instantiation of the weights \cite{Stein1994}.
More recently the characterization of methods for aggregating the uncertainty over the scoring vectors has been studied in \cite{Viappiani2018}.
We also note that the elicitation methods based on minimax regret described in \cite{Boutilier2006} (and in many other recent papers), while not specifically targeted to scoring rules, can be easily adapted (from a technical point of view) to elicit the scoring vector from a committee.

\paragraph{Incomplete profiles}
%In this setting, the system knows a partial preference profile $\ppref$ 
%The partial preference relation $\ppref_i$ represents our knowledge about the preferences of agent $i$.

Lu and Boutilier \cite{Lu2011} assume that the preferences of the voters are only partially known (while the social choice function is known and fixed in advance; it is assumed to be decomposable) and 
 propose to use minimax regret to produce a robust approximation.
Each alternative is associated with a max regret value that measures how far from optimal it could be in the worst case given any completion of the partial profile.
The computation of max regret is facilitated by the fact the score is decomposable.



\section{Background}\label{sec:background}

We introduce the basic concepts.
We assume that there is a set $A$ of $m$ alternatives (for instance products, restaurants, movies, public projects, job candidates, etc.) and $n$ agents (voters); each agent is associated to a preference order.
The goal of the voters is to make a consensus choice, to select a ``winner'' given voter rankings.

%The set of preference orders is called profile and it is denoted by $v$.
The preferences of the agents are supposed to be linear orders (connected, transitive, asymmetric relations) involving the alternatives;
$\pref_i$ denotes the ``real'' preference relation of agent $i$. 
The set $(\pref_1,\ldots,\pref_n)$ is known in the social choice literature as the {\em preference  profile}.
The profile is equivalently represented by $\profile=(v_1,\ldots,v_n)$ where $v_i(j)$ denotes the rank (position) of alternative $j$ in the preference order $\pref_i$. 
With a little abuse of notation, we will use the term profile to refer to either $\profile$ or to the preference relations, depending on the context.
Let $V$ be the set of possible preference profiles (the cartesian product of $n$ linear orders).

A social choice function $f : V \rightarrow 2^A$ associates a profile with a set of winners.
Among the many possible social choice functions, we consider {\em positional scoring rules}, which attach weights to positions; 
%A scoring rule associates each alternative to a score that is given by the sum of points obtained for each voter.
an alternative obtains a score that depends on the rank obtained in each of the preference orders:
\begin{align}
s(x; \profile, \w) = \sum_{j=1}^{n} w_{v_j(x)}
= \sum_{i=1}^{m} \alpha_i w_i . \label{eq:srule}
\end{align}
where $\alpha_i$ is the number of times that alternative $x$ was ranked in the $i$-th position.
The vector $(w_1,\ldots,w_m)$ is called the scoring vector. We assume that the weights constitute a monotonic sequence: $w_{1} \geq w_{2} \geq \ldots \geq w_{m}$.

\medskip
In this work we want to reason about partial preference information.
A partial preference  is encoded by a partial order $\ppref_i$  of voter $i$;
we assume that preference information is truthful, i.e. $a \ppref_i b \implies a \pref_i b$.

A completion of $\ppref_i$ is any linear order $\pref_i$ that extends $\ppref_i$.
Let $C(\ppref_i)$ be the set of completions of $\ppref_i$, that is the set of all complete rankings that extend $\ppref_i$.
An incomplete profile is a set of partial votes %$\textbf{p}=(p_1,\ldots,p_n)$.
$\textbf{p}=(\ppref_1,\ldots,\ppref_n)$.

We let $C(\textbf{p})=C(\ppref_1)\times \ldots \times C(\ppref_n)$ be the set of complete profiles extending $p$.

\medskip
We also assume that the weights of the scoring rule are only partially specified.
Without loss of generality, we assume $w_1=1$ and $w_m=0$.
The preferences of the chair are encoded with linear constraints, for instance one may state
that $w_2>0.5$.
We assume the weight sequence to be convex, that means that the difference between the weight of the first position and the weight of the second position is at least as much as the difference between the weights of the second and third positions, etc. 
\[ \forall i \in \{1,\ldots,n\} \;\; w_i - w_{i+1} \geq w_{i+1}-w_{i+2} \iff  w_i - 2 w_{i+1} + w_{i+2} \geq 0 \]
This is a constraint often used when aggregating rankings in sport competitions.
We use $\mathcal{W}$ to denote the set of convex weight vectors.

% Theoretical complexity of partial completition

% We are given  $\ppref_i $,  a partial preference.
% The maximum regret is considered by assuming an adversary can choose the profile
% \begin{align*}
% \PMR(a,b; p) & = \max_{v \in C(p)} s(b; v) - s(a; v) \\
% \MR(a; p) & = \max_{b} \PMR(a,b) 
% \end{align*}
% 
% We then choose the minimax regret optimal alternative:
% \begin{align*}
% \MMR(p) & = \min \PMR(a,b) \\
% a^{*}(p) & \in \arg\min \PMR(a,b) 
% \end{align*}
%Max regret and minimax regret can be computed using independent completion of partial votes for non-decomposable scoring rules. 

\section[Minimax regret under partial profile and weight information]{Minimax regret under partial profile and weight information}
\label{sec:mmr}

%Robust decision criterion: minimax regret
Minimax regret \cite{Savage1954} is a decision criterion that has been used for robust optimization under data uncertainty \cite{Kouvelis1997} and as well in decision-making with uncertain utility values  \cite{Salo2001,Boutilier2006}.

% we use max regret to measure the quality

% This leads to interesting tradeoffs in elicitation
%The regret-minimizing alternative may not be a possible winner for some voting rules.
% the value of certain preference information is often not worth the cost of obtaining it.
The weights of a scoring rule can model different preferences of the committee. 
For instance, the weights can control the inclination to favour ``extreme'' alternatives (often at either the top or the bottom of the rankings) at the expenses of ``moderate'' alternatives (that are more consistently in the middle part of the rankings).
However in general it can be difficult to set the weights in an appropriate way.

In this paper, we consider a setting where both the voters' preferences and the preferences of the chair about the voting rule are incomplete.


\medskip
The quality of an alternative can be quantified by considering the maximum regret with respect to an adversary that can choose the instantiation of both a complete profile (extending the known preferences of the agents) and of the scoring vectors (associated to the preferences of the committee).

We propose to use the minimax regret as a decision criterion to determine a winner.
Minimax regret \cite{Boutilier2006} has been used for making decisions under utility uncertainty and for preference elicitation.
%Lu and Boutilier \cite{Lu2011} have adopted minimax regret. 

This paper extends the work of  to the simultaneous presence of uncertainty in the agents' preferences and uncertainty in the weights.


Intuitively, the quality of a proposed alternative $a$ is how far from optimal $a$  could be in the worst case, given the current knowledge about the voting rule and about the voters' preferences.

The maximum regret is considered by assuming an adversary can choose both 1) to extend the partial profile into a complete profile 2) can instantiate the weights choosing among any feasible weight vector in $W \subseteq \mathcal{W}$.

We formalize the notion of minimax regret in multiple steps.
First of all, $\Regret(x, \profile, \w)$ is the loss or ``actual'' regret  of selecting $x$ as a winner instead of choosing the optimal alternative under $\profile$ and $\w$:
\[\Regret(x, \profile, \w) = \max_{y} s(y; \profile,\w) - s(x; \profile, \w).\]

The pairwise max regret of $x$ relative to $y$ given partial profile $\pprofile$ and the space of weights $W$
$\PMR(x,y;\pprofile,W)$ is the worst-case loss under all possible realizations of the full profile {\em and} all possible instantiations of the weights:
\begin{align}
\PMR(x,y; \pprofile, W) & = \max_{\w \in W} \max_{\profile \in C(p)} s(y; \profile,\w) - s(x; \profile,\w).
\end{align}

Max regret $\MR(x;\pprofile,W)$ is the worst-case loss of $x$. It is the loss occurred by an adversarial selection of a complete profile $\profile$ extending $\pprofile$ and a selection of $\w \in W$ to maximize the loss between $x$ and the true winner under $\profile$ and $w$.
\begin{align}
\MR(x; \pprofile, W) & = \max_{y \in A} \PMR(x,y; \pprofile, W)\\
& = \max_{\w \in W} \max_{\profile \in C(p)} \Regret(x, \profile, \w).
\end{align}

Finally,  $\MMR(\pprofile,W)$ is the value of minimax regret under $\pprofile$ and $W$, obtained when recommending the minimax optimal alternative $x^*$:
\begin{align*}
\MMR(\pprofile,W) & = \min_{x \in A} \MR(x;\pprofile,W) \\
x^{*}(\pprofile,W) & \in \arg\min_{x \in A} \MR(x;\pprofile,W) 
\end{align*}
By recommending the alternative associated with minimax regret, we can provide a recommendation that gives worst-case guarantees, giving some robustness in face of uncertainty (due to both not knowing the agents' preferences and the weights used in the aggregation). 

Notice that if $MMR(\pprofile, W)=0$, then $x^{*}(\pprofile,W)$  is a necessary co-winner.

% Add some general remarks about using minimax regret
\subsection{Computation of minimax regret}
In order to compute pairwise maximum regret and therefore minimax regret, we adapt the reasoning from \cite{Lu2011} so that we decompose the $\PMR$ into the contributions that is associated to each agent.
The settings is however more challenging due to the presence of uncertainty in the weights.


Scoring rules are additively decomposable.
%A scoring rule associates each alternative to a score that is given by the sum of points obtained for each voter.
Let $s(x; v_j,\w)=w_{v_j(x)}$ be the number of points that $x$ obtains in the ranking $v_j$ (see Equation \ref{eq:srule}), that is the weight of position $v_j(x)$.
Obviously we have 
\[ s(x; \profile, \w) = \sum_{j=1}^n s(x; v_j,\w). \]

By exploiting the decomposition of the score in terms of votes, we write the actual regret of choosing $x$ instead of $y$ as:
\[
s(y; \profile,\w) - s(x; \profile, \w) = [\sum_{j=1}^n s(y; v_j,\w) - s(x; v_j,\w)]
\]
and  can rewrite $\PMR$ as follows:
\begin{align*}
\PMR(x,y; \pprofile, W) &= \max_{\w \in W} \max_{\profile \in C(\pprofile)} [ s(y; \profile,\w) - s(x; \profile,\w) ] = \\
&=  \max_{\w \in W} \sum_{j=1}^{n} \max_{v_j \in C(\succ_j^p)} [s(y; v_j,\w) - s(x; v_j,\w)]=\\
&=  \max_{\w \in W} \sum_{j=1}^{n} \max_{v_j \in C(\succ_j^p)} [w_{v_j(y)} - w_{v_j(x)}] \\
\end{align*}
Given our hypothesis, for all pairs of alternatives, there exist completions of the partial preferences $\ppref$ that maximize the PMR and that do not depend on the weights. 
That is, we can exhibit, for each voter $j$, a completion $v_j$ such that $\forall \w, \forall v'_j \in C(\ppref_j): [w_{v_j(y)} - w_{v_j(x)}] \geq [w_{v'_j(y)} - w_{v'_j(x)}]$.

Let $A^+=\{ i \ | \ y \ppref_i x\}$ be the set of agents for which we know that $y$ is preferred to $x$ (positive contribution to pairwise regret), $A^-=\{ i \mid x \ppref_i y\}$ 
be the set of agents for wich we  know that $x$ is preferred to $y$ (negative contribution) and $A^?=\{ i \mid x \pinc_i y\}$ the remaining case, where the preference between $x$ and $y$ is not known.
Consider how the adversary will complete the partial orders:
\begin{itemize}
 \item $j \in A^+$: If we know that agent $j$ prefers $y$ to $x$ then the adversary will complete the partial order of agent $j$ by placing as many alternatives as possible between $y$ and $x$.
 The way the partial order is completed does not depend on the weights.

 \item $j \in A^?$: If we do not know whether $x$ or $y$ is preferred by agent $j$ then the adversary will place $y$ before $x$ in the linear order and this case reduce to the first one; therefore also in this case the completion of the partial order can be done independently of the choice of $w$.

 \item $j \in A^-$: If we know that agent $j$ prefers $x$ to $y$ then the adversary will place as few alternatives as possible between $x$ and $y$.
 We define $U$ as the set of alternatives that are incomparable with $x$ and $y$ according to $\ppref_i$. Since weights are assumed to be convex, the adversary will place all alternatives in $U$ as better than $x$.
\end{itemize}
In summary, some best completion $\pref$ satisfies two properties: (1) for all $c \pinc x$, $c \pref x$; and (2) for all $c \pinc y$, if not $c \pref x \pref y$ then $y \pref c$. These two properties are intuitively understandable by observing that maximizing the PMR requires placing $x$ as low as possible, hence the first property; and $y$ as high as possible, hence the second property, with the exception that sometimes it is not possible to satisfy both desires and noting that the first desire is more important by convexity of the weights. A proof that this reasoning is correct is in \cref{sec:prfCompl}.

The space of feasible weights $W$ is encoded with linear constraints that model the preferences of the committee.
Therefore the pairwise maximum regret can be computed with a linear program.

\subsection{Linear program under the convex assumption}

By solving a sequence of pairwise max regret computations is possible to determine the minimax regret solution.
Each PMR is computed using a linear program.
The decision variables correspond to the weights attached to the different positions.
Constraints are on the feasible parameters (the ``weights'' of the scoring rules); contraints represent the preferences of the chair about the scoring rule.

Let $\hat{v}$ be the compute profile computed according to the above procedure, and  $\hat{v}_j$ the $j$-th element (the linear order extending the partial order $p_j$ of the $j$-th voter).
The PMR can be written as:
\[ \PMR(x,y) = \sum_{j=1}^n w_{\hat{v}_i(y)} - w_{\hat{v}_i(x)} 
= \sum_{i=1}^m \alpha_i w_i \]
where the coefficient $\alpha_i$ is the number of times $y$ is in the $i-th$ position minus the number of times $x$ is the in the $i$-th position in the rankings of the completed profile $\hat{v}$:
\[ \alpha_{i} = \sum_{j=1}^{n}  I[\hat{v}_{j}(y)=i] - I[\hat{v}_{j}(x)=i]\]
where $I$ is the indicator function.
The linear program is then the following:
\begin{align}
\max & \sum_{i=1}^m \alpha_i w_{i}\\
\text{ s.t. } & w \in W
\end{align}

\subsection{Minimax regret without the convex assumption}

\begin{itemize}	
	\item (will probably go to a later section, or to the appendix)
	\item Mixed integer program to solve minimax regret without the convexity
 	\item Approximations ?
\end{itemize}

Let $\hat{v}_i$ be the linear order extending $p_i$ according to the above procedure (described in \cite{Lu2011}).
Then PMR can be written as follows:
\[ \PMR(x,y; \pprofile, W) = \max_{\w \in W} \Big \{ \max_{v_j \in C(\succ_j^p)} [w_{v_j(y)} - w_{v_j(x)}]  + \sum_{j \in A^+, j \in A^?} [w_{\hat{v}_j(y)} - w_{\hat{v}_j(x)}] \Big \} \]


We compute pairwise maximum regret by considering binary variables to represent optimization choices related to where to position the alternatives.
We also have numerical variables to represent the weights of the scoring rule.
%Since the objective is to maximize pairwise regret...

 The objective function can be written as:
 \[ \max \sum_{l=1}^n B^j_l w_l -  B^j_l w_l \]

We use enconding trick in order to solve the problem.
We replace the multiplicative terms by new variables.
\[ V_{l}^{j} \sim B^j_l w_l  \]

To impose the desired behavior:
\begin{align*} 
V_{l}^{j} \leq B^j \\
V_{l}^{j} \leq w_l
\end{align*}
The expression $I^j_l w_l$ evaluates to $w_l$ if $I^j_l = 1$, and to $0$ otherwise.
  
We write $w \in W$ as a shourtcut to represent the constraints that the weights are chosen to be in the feasible set.
%Variable $I^j$ associated with the constraint $0 \leq I \leq |U^j|$.
 Finally, the following is the optimization problem that compute the value $\PMR$.
 The variables are $w$, $V$, $B$,...
\begin{align}
Z := \max & \sum_{l=1}^m  V_{l}^{j,+} - V_{l}^{j,-}\\
\text{ s.t. } & w \in W  \\
& \sum_{B=i_{1}}^{i_{2}} I^{j}_{l} = 1 & \forall j \\
& V_{l}^{j,+} \leq B^j_{l}  & \forall l,j \\
& V_{l}^{j,+} \leq w_l & \forall l,j \\
& V_{l}^{j,-} \geq w + B_{l}^j - 1 & \forall l,j \\
& V_{l}^{j,-} \geq 0 & \forall l,j\\
\end{align} 
The optimization program can be solved by any suitable MILP solver.

\begin{claim}
The $\PMR$ is computed using the above optimization problem.
\end{claim}

 
\section{Interactive Elicitation} \label{sec:elicit}

If the available information is too limited, the potential error associated with the robust winner (i.e., its max regret) may be unacceptable.

Minimax regret can be used to guide the elicitation process.
As termination condition of elicitation, we can check whether minimax regret is lower than a threshold. If we wish optimality, we can perform elicitation until minimax regret drops to zero.

At each step, the system needs to decide whether to ask a question to one of the agents or ask a question to the chair about the voting rule

In this Section, we describe different strategies to determine informative queries to ask next, with the goal of reducing $\MMR(\pprofile,W)$ quickly.

We propose an regret-based incremental elicitation method...

\paragraph{Query types}
We distinguish between queries asked to the voters and questions asked to the chair.

Questions to the voters: it is natural to consider comparison queries asking to compare two alternatives

Another common type or queries are {\em top-k}, asking to each voter his $k$ most alternatives.


Questions to the committee: we consider questions that refine our knowledge about the weighting vectors $w$.

In particular, we want to acquire constraints of the type:
\[ w_{i} - w_{+1i} \geq \lambda (w_{i+1} - w_{i+2}) \]

\paragraph{Elicitation strategies}

We develop some elicitation strategies for simultaneous elicitation of voters' preferences and of the scoring rule.
Starting from some initial partial knowledge, our goal is to learn both the scoring rule function and the agents' preferences.
While it is of course possible doing full elicitation of the weights and afterwards elicit the agents' preferences (or the other way around) we propose an interleaved approach.
In our interactive  protocol for simultaneously eliciting the preferences of the chair about the voting rule and the voters' preferences about the alternatives.
Indeed, it can be beneficial to interleave questions asked to the committee and questions asked to voters, depending on which is estimated to be more informative.

Answers given by the committee about the scoring rule refine our knowledge of the weights $w_1,\ldots,w_n$, while
answers given by one of the agents refine our knowledge about the agent's preferences.

At each step we need to decide whether we want to ask a question to the committee or to one of the agents (and to which agent in particular). We can ask comparison queries to the agents and questions comparing the differences of weights to the committee. 

In the experiments we want to compare the interleaved approach with a baseline challenger, a method  that elicits the preferences of the voters first and then the voting rule (or the other way around)

%Type of questions that we can ask to the chair:	bound queries (Is this alternative among your top-k most preferred items?), comparison queries (do you prefer alternative x or alternative y?).

% we discuss the different forms of queries and develop several query strategies 




\paragraph{Query methods}
We consider different strategies to determine the next question to ask given the current information.
%{\em Some ideas: decompose the regret into two components, one due to $\w$ and one due to $\pprofile$, and ask a question to the chair / or to one of the agents depending on which is highest}

%We consider strategies of the following form
%{\em if} condition {\em then} ask comparison query {\em else} ask a committee query
%Define a score associated to each potential query that we may ask.

\begin{itemize}
\item {\em Current solution strategy}: consider the solution of the minimax regret game, 
 $(x,y,\w^{a},\profile^{a})$, where $x$ is the minimax regret optimal alternative, $y$ the adversarial choice, $\w^{a}$ the weights, and $\profile^{a}$ the profile completed by the adversary.

Ask a question to compare $x$ with $y$ to an agent.

% Determine the part of ``regret'' due to uncertainty in $w$
% Determine the part of ``regret' due to uncertainty in $p$
 
 \item One possibility is to consider the MMR {\em a posteriori}. Assume that the different answers to a query induce the possible sets to be $(\pprofile_1,W_1)$ and $(\pprofile_2,W_2)$, then the score according to worst-case maximum regret is:
\[\SCORE(x)= \max_{i=1,2} \MMR(\pprofile_i,W_i) \]
In this case, the query with least value is chosen.

What is the complexity of this strategy? Let's define $Q$ as the set of all possible queries we can address to the agents and to the committee. The worst case is represented by the situation in which we do not have any information about both the agents' preferences and the weights constraints. In this case we can address $\binom{m}{2}=\frac{m(m-1)}{2}$ questions to each agent. Moreover, we need to ask at least $m$ questions to the committee. Then, each question induces two possible pairs of $(\pprofile,W)$ for each of which we compute the $\MMR$, whose worst case complexity is $O(nm^3)$. Thus, the cardinality of $Q$ in the worst case is $\approx n \cdot \frac{m(m-1)}{2} + \lambda m$, and the worst case time complexity of the strategy is $O(n^2m^5)$.

\item Two phase method.
Ask a predefined (non adaptive) sequence of questions in order to learn the weights $w$ of the scoring rule).
Then use minimax regret as in Lu and Boutilier.

%\item Non-interleaved regret method: comparison with a method based on minimax regret, but not interleaved. 

\item Non-interleaved non-regret strategies (useful as benchmarks).	
	\begin{itemize}
		\item Random strategy: randomly chooses an agent $i$ and a comparison query such that $x \pinc_i y$.
		\item Volumetric strategy: chooses an agent $i$ and a query that maximizes the number of new pairwise preferences revealed given the worst response.
	\end{itemize}
\end{itemize}

\section{Empirical Evaluation} \label{sec:experiments}

% We can stop elicitation when minimax regret is sufficiently small.
We test the elicitation protocols in randomly generated datasets and real datasets. % (sushi and iris).
We evaluate the proposed method using the following simulated protocol.

\begin{itemize}
 \item Randomly generate the true preferences of the users (i.e. the linear orders) and the weights associated with the committee's preferences on the scoring rule
 \item For each of the elicitation strategy, simulate the elicitation by asking the queries selected by the strategy.
 
 \item Compare performance with respect to decrement in max regret, real loss
\end{itemize}

Test with different values of $m$ (number of alternatives) and $n$ (number of agents); test with different population sizes, different number of alternatives, etc.

Make one test assuming convex sequences of weights, and others without this assumption.

Comparison between our interleaved strategy and a strategy, still based on minimax regret  but that is not interleaved; also compare to some heuristic baselines.

\section{Conclusions}  \label{sec:conclusions}
%  We have proposed the use of minimax regret as a means of robust winner determination to support the informational approximation of voting rules, as well as to guide the process of incremental elicitation of voter preferences.
%In this paper we have proposed the use of minimax regret as a way to determine a winner in a robust way when considering uncertainty on both the voting rule and the voters' preferences.

In this paper we have considered a  social choice setting with partial  information about the voter's  
preferences and as well a partially specified voting rule.
We have proposed the use of minimax regret as a means of robust winner determination in this setting, and as well as to guide the process of incremental elicitation of voter preferences.
Our experimental results on randomly generated and real world data sets show that regret-based elicitation is effective and allow to find a near-optimal consensus choice in a limited number of steps.
%Regret-based elicitation allows to determine near-optimal winners using only few information about the voters' preferences.
We mention some  important directions for future works.
First of all, further development of elicitation strategies, considering alternative heuristics, is an important direction. 
Second, we are interested in extending elicitation of voting rules going beyond scoring rules.
A third direction is that of considering probabilistic methods for elicitation.
Finally, we are interested in studying the effect of strategic agents, that may not report their true preferences.
% distribution-free heuristics

% Acknowledgements: We thank the reviewers for comments helping to improve the paper. 
%{\small
\bibliography{biblio}
\bibliographystyle{plain} 
%}

\pagebreak
\appendix
\section{Minimax Computation under Convex Assumption} 

Refer to \cite{Lu2011}
The goal is to choose as a winner the alternative $x^*$ whose worst case loss is minimal under all possible realizations of the full profile and all possible choices of weights. 
Assume hereinafter the selected weights sequence $\w \in W$ to be convex. 
In order to compute the minimal max regret $\MMR(\pprofile)$ under partial profile $\pprofile$ we need to compute the pairwise max regret between all pairs of alternatives $(x,y)$, where $x$ is a proposed winner and $y$ is the ``adversary'' alternative. Indeed, the construction of $\PMR(x,y,\pprofile,\w)$ can be viewed as an adversary's attempt to maximize the regret of choosing $x$ instead of $y$. 
For doing this, he can choose a completion $\profile_i \in C(\pprofile_i)$ of the partial profile and a (feasible) scoring vector $\w$ that maximize the contribution of the voter $i$ to $\PMR(x,y,\pprofile,\w)$. Let us now analyze how it could be done depending on the relation between alternatives $x$ and $y$ in $\pprofile_i$. 
\begin{itemize}
	\item $x \succ_i^\pprofile y$
	\newline If we know $x$ is preferred to $y$ and we choose $x$ as a winner, $\pprofile_i$ contribution to $\PMR(x,y,\pprofile,\w)$ must be negative. In this situation, our adversary can only try to minimize this advantage by minimizing the positional gap between the two alternatives. To achieve that, he can arbitrary place all the alternatives preferred to $x$ above $x$, together with all the ones with unknown relation to $x$. Moreover, he can place all the alternatives less preferred to $x$ and with unknown relation to $y$ below $y$. We can summarize it for each $q \in A$ as follows:
	\begin{align*}
	q \succ_i^\pprofile x \vee q \ ?_i^\pprofile \ x \ & \Rightarrow \ \uparrow_x \\
	x \succ_i^\pprofile q \wedge ( q \ ?_i^\pprofile \ y \vee y \succ_i^\pprofile q) \ & \Rightarrow \ \downarrow_y \\
	x \succ_i^\pprofile q \succ_i^\pprofile y \ & \Rightarrow \ \text{in between} \\
	\end{align*}
	It is worth noting that when the relation between $q$ and $x$ is not known in the partial profile, the adversary takes advantage by placing $q$ above $x$ only under the assumption of convex weight sequences.
	\item $y \succ_i^\pprofile x$
	\newline If $y$ is preferred to $x$ the construction proceeds similarly to the previous case, but now the adversary takes advantage by maximizing the gap between $x$ and $y$ placing as much alternatives as he can between the two. We can summarize the procedure for each $q \in A$ as follows:
	\begin{align*}
	q \succ_i^\pprofile y \ & \Rightarrow \ \uparrow_y \\
	x \succ_i^\pprofile q \ & \Rightarrow \ \downarrow_x \\
	(y \succ_i^\pprofile q \vee y \ ?_i^\pprofile \ q) \wedge (q \succ_i^\pprofile x \vee q \ ?_i^\pprofile \ x) \ & \Rightarrow \ \text{in between} \\
	\end{align*}
	\item $x \ ?_i^\pprofile \ y$
	\newline If the partial profile $\pprofile_i$ does not specify the relation between $x$ and $y$, the advantage is maximized by ordering $y$ over $x$ and maximizing the gap between them following the procedure for the case $y \succ_i^\pprofile x$.
\end{itemize}

\section{Dropping the Convex Assumption}
\subsection{Profile completion}
What if the sequence of weights is not convex? When $y \succ_i^\pprofile x$ or $x \ ?_i^\pprofile \ y$ weights do not influence the arbitrary placement of alternatives. Please remind we are working under the assumption that weights constitute a monotonic non-increasing sequence. Thus, there is no way for the adversary to take advantage from the weights distribution in order to increase the gap between $y$ and $x$ besides placing as much alternatives as he can between the two. The only case in which weights can influence the positional gap between $x$ and $y$ is when $x \succ_i^\pprofile y$ and $q \ ?_i^\pprofile \ x$. For convex sequences we place such alternatives $q$ above $x$, but it is not obvious that this is the best option for other sequences. For example, suppose $x$ and $y$ are ranked respectively in first and second position in the partial profile and we wonder where to place an alternative $q$ with unknown relation to $x$ (and thus to $y$). Suppose also that in the weight sequence the distance between the first and second positions is much lower than the one between the second and the third ones. In this case, placing $q$ above $x$ does not minimize the gap between $x$ and $y$ but we want, instead, to place $q$ below $y$.
\newline The constraints expressed by the chair may result in a set of feasible vectors such that none of them forms a convex sequence. In this case we need to analyze the particular sequence of weights in order to decide how to maximize the adversary advantage. Before going into details, let us define $A$ as the set of alternatives (if any) preferred to $x$, $B$ as the set of alternatives preferred to $y$ but not to $x$, and $U$ the set of those with unknown relation to both $x$ and $y$. The idea is to determine the positions that minimize $x$'s advantage over $y$ and then place some of the alternatives in $U$ above $x$ and some below $y$ in order to get that desired ranking. Since we cannot change the order of the alternatives in the set $B$ we know that $x$ and $y$ are separated exactly by $|B|$ positions (the adversary would not take any advantage by adding alternatives between them). So, starting from the position of $x$ in the partial completion of $\pprofile_i$ computed so far ($\hat{\profile}_i$), we find the two positions separated by $|B|$ alternatives whose weights difference is the lowest. Note that we can only add $|U|$ alternatives so we can check only until the position $\hat{\profile}_i(x)+|U|$. Algorithm \ref{alg:splittingU} shows the procedure described.

It is easy to see that we check at most $|U|$ positions. In the worst case the size of $U$ is equal to $m-2$, thus the procedure can be computed in $O(m)$ time. This cost does not affect the minimax regret computation time complexity that remains $O(nm^3)$.

\begin{algorithm}[h] 
	\caption{Placing alternatives in $U$ without Convex Assumption}
	\label{alg:splittingU} 
	\begin{algorithmic}
		\Require $x$, $y$, $\hat{\profile}_i$, $\w$, $U$, $B$
		\Ensure $\profile_i \in C(\pprofile)$
		\Statex
		\State $ j \gets 0$;
		\State $ i \gets \hat{\profile}_i(x)$;
		\State $ \mathit{posmin} \gets i$;
		\State $ \mathit{min} \gets \w(i) - \w(i+1+|B|)$;
		\While {$( j \leq |U| )$}
		\If{ $(\w(i+j)-\w(i+1+|B|+j) < \mathit{min})$ }
		\State $ \mathit{min} \gets \w(i+j) - \w(i+1+|B|+j)$;
		\State $ \mathit{posmin} \gets i+j$;
		\EndIf
		\EndWhile
		
		\State $U_{\mathit{abovex}} \gets (i-\mathit{posmin}) \text{ alternatives} \in U $;
		\State $U_{\mathit{belowy}} \gets U \setminus U_{\mathit{above}}$;
		\Statex
		\State $\profile_i \gets place(\pprofile_i,U_{\mathit{abovex}},U_{\mathit{belowy}})$;
		\Statex \Return $\profile_i$
		
	\end{algorithmic}
\end{algorithm}

%\subsection{Profile completion, again}
% %{\bf \em TODO: still have to find out exactly how to do it}
% 
% We introduce a set integer variables $I^i$, one for each position $i$.
% Let $U^j$ be, for the agents in $A^-$, the alternatives that, in the partial order $\succ^p_j$ of some agent $j \in A^-$, are incomparable with $x$ and $y$.
% \[ \sum_{l=1}^n I^j_l w_l \]
% Variable $I^j$ associated with the constraint $0 \leq I \leq |U^j|$.
% 
% We provide the following MIP (mixed integer linear program).
% 
%% Use linearization techniques to handle the multiplications...
%
%
%%\section{Even more fun}
%%We can consider different types of questions: asking to compare a pair of alternatives, asking about top-k alternatives.
%

\section{Proof of completion}
\label{sec:prfCompl}
Given $w$ and ${\pref} \in C(\ppref)$, let $w[\pref]$ denote $w_{|\pref(y)|} - w_{|\pref(x)|}$. \commentOC{Changing the notation to slightly reduce the number of symbols, to be discussed.}

Given ${\pref} \in C(\ppref)$, define $\pref^1$ as $\pref$ except that the elements in $C = \{c \pinc x \land x \pref c\}$ come just above $x$ in $\pref^1$, respecting in $\pref^1$ their internal ordering in $\pref$. We show first that $\pref^1$ is an element of $C(\ppref)$; and second that $\forall w: w[\pref^1] \geq w[\pref]$. 

First, it is an element of $C(\ppref)$ as it does not contradict $\ppref$. To show this, recall first that $\pref$ does not contradict $\ppref$. Left to show is that $\forall c \in C, d \notin C: x \pref d \pref c \Rightarrow d \pinc c$ (thus any element $d$ whose relation with $c$ has changed from $\pref$ to $\pref^1$ were incomparable with $c$ in $\ppref$). Consider any such pair $c, d$. As $d \notin C$, $\lnot(d \pinc x)$ or $d \pref x$. From the hypothesis, $d \pref x$ is excluded. 
As $\pref$ extends $\ppref$, $\lnot(d \ppref x)$ and $\lnot (c \ppref d)$. Because $\lnot (d \pinc x)$, $x \ppref d$. Thus, $\lnot (d \ppref c)$, otherwise by transitivity $x \ppref c$. The conclusion now follows from $\lnot (c \ppref d)$ and $\lnot (d \ppref c)$.

Second, in $\pref^1$, compared to $\pref$, $x$ is $|C|$ positions lower, and $y$ is at most $|C|$ positions lower, depending on where $y$ was in $\pref$. Hence, by convexity of the weights, $w[\pref^1] \geq w[\pref]$.

Now define $\pref^2$ as $\pref^1$ except that the elements from $C' = \{c \pinc y \land \lnot (c \pref^1 x \pref^1 y) \land c \pref^1 y\}$ move just below $y$, respecting in $\pref^2$ their internal ordering in $\pref^1$. Observe that this move keeps property (1), that was satisfied by construction in $\pref^1$, intact, and satisfies property (2). The rest of the reasoning is similar to the previous move, as the situations are symmetric. (To be checked?) Hence, ${\pref^2} \in C(\pref)$ and it satisfies both properties.

Given any $x, y, w$, as $C(\pref)$ has an element maximizing $w[.]$ (by finiteness of the set), the above reasoning shows that some element in $C(\pref)$ satisfies both properties and maximizes $w[.]$. And any element in $C(\pref)$ satisfying both properties attribute the same positions to $x$ and $y$, thus, maximizes $w[.]$.

\section{Considerations on weights}
\label{sec:weights}
Let us consider a monotonic non-increasing sequence of weights: $w_{1} \geq w_{2} \geq \ldots \geq w_{m}$. Without loss of generality, we can assume $w_1=1$ and $w_m=0$.

\begin{claim}
	\label{clm:wsequence}
	If the weight sequence is convex then $w_{1} > w_{2}$.
	\[\forall i \in \{1,\ldots,m\} \;\; w_i - w_{i+1} \geq w_{i+1}-w_{i+2} \Rightarrow w_{1} > w_{2} \geq \ldots \geq w_{m}\] 
\end{claim}
\begin{proof}
	By contradiction let assume $w_{1} = w_{2}$ then 
	\begin{align*}
	w_{1} - w_{2} \geq w_{2} - w_{3} &\geq \dots \geq w_{m-1} - w_{m} \\
	1 - 1 \geq 1 - w_{3} &\geq \dots \geq w_{m-1} - 0 \\
	0 \geq 1 - w_{3} &\geq \dots \geq w_{m-1}
	\end{align*}
	At this point either $0\leq w_{3}<1$ or $w_{3}=1$. In the first case 
	\[0 \ngeq 1 - w_{3}\]
	This breaks the convexity assumption so it is impossible.
	In the second case, by definition there is a $w_{i} \neq 1$ where $2 < i \leq m$. So it would be 
	\[0 \ngeq 1 - w_{i}\]
	for some $i$. Again, the convexity is not satisfied.
\end{proof}

\begin{corollary}
	\label{cor:weq}
	If the weight sequence is convex and $w_{i} = w_{i+1}$ for some $i$, then $w_{j}=0 \ \forall \
	j=i, \dots m$.
\end{corollary}


\section{Querying the committee}
Suppose our query strategy suggests us to ask the committee the following query:
\[ w_{2} - w_{3} \geq 2(w_{3} - w_{4}) \]
Then we can transform it in:
\begin{align}
\label{eqn:juryquery}
w_{2} - w_{3} &\geq 2 \cdot w_{3} - 2 \cdot w_{4} \notag \\
w_{2} + 2 \cdot w_{4} &\geq 3 \cdot w_{3} 
\end{align}
and ask the committee if they would prefer as a winner an alternative ranked first one time and third three times rather than an alternative ranked second four times.

Another way to query the committee, a more concrete one, is to present them a profile representing the situation described by the query and then deduce its answer from the selected winner. Obviously we have to be sure to choose a profile where only the alternatives we are interested in could be pick as winners. Therefore, we need a systematic way to construct a profile that reflects the situation outlined by the query for two alternatives and the others are not better than them.


Assume we have a profile of $3$ voters ranking $4$ alternatives. We can represent it by columns where each of them represents the preference ordering of one voter.
\[
\begin{array}{ccc}
v_1
& v_2
& v_3 \\
\midrule 
c
& d
& c \\
a
& c
& d \\
b
& b
& b \\
d
& a
& a \\
\end{array}
\]

Assuming anonymity, we can also write the profile expressing for each alternative $i \in A$ the number of voters placing it at a given rank.

\[
\begin{array}{ccccc}
& 1^\circ
& 2^\circ
& 3^\circ
& 4^\circ \\
\cmidrule{2-5}
a 
& 0
& 1
& 0
& 2 \\
b
& 0
& 0
& 3
& 0 \\
c
& 2
& 1
& 0
& 0 \\
d
& 0
& 1
& 1
& 1 \\
\end{array}
\]

Recalling the query (\ref{eqn:juryquery}) we are considering as an example, it is easy to see that in the current profile alternatives $a$ and $b$ represent the situation as described by the query. Therefore, if after proposing this profile to the committee the winning alternative turns out to be $a$ then we know that $w_{2} - w_{3} > 2(w_{3} - w_{4})$; if, instead, the winner is $b$ we know that $w_{2} - w_{3} < 2(w_{3} - w_{4})$ and if both alternatives are picked as winners then $w_{2} - w_{3} = 2(w_{3} - w_{4})$. 

Nevertheless, in this example it is clear that $c$ will always be preferred to other alternatives (see Claim \ref{clm:wsequence} in Section \ref{sec:weights}). To see it we can express for each alternative the number of voters placing it at a given rank or at a higher one.

\[
\begin{array}{ccccc}
& \geq 1^\circ
& \geq 2^\circ
& \geq 3^\circ
& \geq 4^\circ \\
\cmidrule{2-5}
a 
& 0
& 1
& 1
& 3 \\
b
& 0
& 0
& 3
& 3 \\
c
& 2
& 3
& 3
& 3 \\
d
& 0
& 1
& 2
& 3 \\
\end{array}
\]


\begin{claim}
	Consider a set $A$ of $m$ alternatives and let $r_k(i)$ be the number of times the alternative $i$ obtains a rank $k$ or a higher one. Consider two alternatives $ i,j \in A$, if $\forall \ k=2, \dots,m \ r_k(i)\geq r_k(j)$ and $r_1(i) > r_1(j)$ then $i$ is always preferred to $j$ for any choice of weights.
\end{claim}

\begin{proof}
	For our assumptions we know the sequence of weights is monotonic non-increasing and convex. Moreover, for the Claim \ref{clm:wsequence} in Section \ref{sec:weights}, we know that $w_1 > w_2$. Therefore, even in the worst case where $r_k(i) = r_k(j) \ forall \ k=2, \dots,m$ the sum of weights for alternative $i$ cannot be lower than the one for $j$. It is worth noting that we cannot say anything when $r_1(i) = r_1(j)$. Indeed, as said in Corollary \ref{cor:weq}, all the weights for other position but the first one can be equal, thus the number of voters ranking the alternatives at a certain position does not matter anymore.	
\end{proof}

So the strategy for querying the committee is to use two alternatives $i$ and $j$ to represent the query and complete the profile such that the other alternatives are all dominated by them. An algorithmic approach is to start from the initial profile and then add as many voters as needed that rank $i$ and $j$ as their top choices and the other alternatives afterwards. As an example let consider again the query \ref*{eqn:juryquery}. We want the committee to choose between $a$ or $b$:

\[
\begin{array}{ccccc}
& 1^\circ
& 2^\circ
& 3^\circ
& 4^\circ \\
\cmidrule{2-5}
a 
& 0
& 1
& 0
& 2 \\
b
& 0
& 0
& 3
& 0 \\
\end{array}
\]

We add voters in order to increase the number of times $a$ and $b$ are ranked at first position. Please note we must maintain these scheme, so every add of a position to the ranking of $a$ must correspond to the same in the ranking of $b$.

\[
\begin{array}{cccccc}
v_1
& v_2
& v_3 
& v_4
& v_5
& v_6 \\
\midrule 
a
& b
& c 
& d
& a
& b \\
c
& a
& d
& c
& b
& a \\
b
& d
& b
& b
& d
& c \\
d
& c
& a
& a
& c
& d \\
\end{array}
\]

\[
\begin{array}{ccccc}
& 1^\circ
& 2^\circ
& 3^\circ
& 4^\circ \\
\cmidrule{2-5}
a 
& 2
& 2
& 0
& 2 \\
b
& 2
& 1
& 3
& 0 \\
c
& 1
& 2
& 1
& 2 \\
d
& 1
& 1
& 2
& 2 \\
\end{array}
\]

\[
\begin{array}{ccccc}
& \geq 1^\circ
& \geq 2^\circ
& \geq 3^\circ
& \geq 4^\circ \\
\cmidrule{2-5}
a 
& 2
& 4
& 4
& 6 \\
b
& 2
& 3
& 6
& 6 \\
c
& 1
& 3
& 4
& 6 \\
d
& 1
& 2
& 4
& 6 \\
\end{array}
\]
\textbf{Remarks:}
\begin{itemize}
	\item We are considering $\lambda \in \mathbb{N} \setminus \{0\}$ but we could be interested in a real number. \textit{Solution}: we can multiply both sides.
\end{itemize}

\end{document}  
